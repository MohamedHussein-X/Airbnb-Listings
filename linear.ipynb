{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c4e42d-0b5a-49a5-ba3d-ae47b519ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d788062-0eda-43cf-8521-ab2b4348d320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.11/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f71f9e1-4f3f-477b-8f62-7eec77fcf1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ba00ab-b34e-4a5d-a467-2295dce88635",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('LinearReg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3a58ae-908b-4f25-87d1-668af3e7f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('cleaned_listings.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39b5960-68ab-4a06-b2ef-65827a25820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'summary', 'longitude', 'latitude', 'space', 'description', 'instant_bookable', 'neighborhood_overview', 'neighbourhood_cleansed', 'host_id', 'host_name', 'host_since', 'host_response_time', 'street', 'zipcode', 'review_scores_rating', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'reviews_per_month', 'amenities', 'cancellation_policy', 'number_of_reviews', 'price']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cac7e1-ab81-4c5b-b059-84a8efbbbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df[['room_type','property_type','bedrooms','amenities','number_of_reviews', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21fc94d-f995-4ef6-b196-2bba8c5aeb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_type', 'property_type', 'bedrooms', 'amenities', 'number_of_reviews', 'price']\n"
     ]
    }
   ],
   "source": [
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90472c07-d463-4a6c-9bc9-ff1dc00d570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-----+\n",
      "|room_type      |property_type|bedrooms|amenities                                                                                                                                                                                                                                          |number_of_reviews|price|\n",
      "+---------------+-------------+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-----+\n",
      "|Entire home/apt|Apartment    |1.0     |{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"Air Conditioning\",Kitchen,Heating,\"Family/Kid Friendly\",Washer,Dryer}                                                                                                                                 |207              |85.0 |\n",
      "|Entire home/apt|Apartment    |1.0     |{TV,Internet,\"Wireless Internet\",Kitchen,\"Free Parking on Premises\",\"Buzzer/Wireless Intercom\",Heating,\"Family/Kid Friendly\",Washer,Dryer,\"Smoke Detector\",\"Carbon Monoxide Detector\",\"First Aid Kit\",\"Safety Card\",\"Fire Extinguisher\",Essentials}|43               |150.0|\n",
      "+---------------+-------------+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc8ecff-084f-43ca-9bda-48ee31d3404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           amenities|count|\n",
      "+--------------------+-----+\n",
      "|                  {}|   22|\n",
      "|{Internet,\"Wirele...|   11|\n",
      "|{TV,\"Cable TV\",In...|   10|\n",
      "|{TV,\"Cable TV\",In...|    6|\n",
      "|{TV,Internet,\"Wir...|    6|\n",
      "|{Internet,\"Wirele...|    6|\n",
      "|{TV,\"Cable TV\",In...|    6|\n",
      "|{TV,Internet,\"Wir...|    6|\n",
      "|{TV,\"Cable TV\",In...|    5|\n",
      "|{TV,Internet,\"Wir...|    5|\n",
      "|{TV,\"Cable TV\",In...|    5|\n",
      "|{TV,Internet,\"Wir...|    5|\n",
      "|{Internet,\"Wirele...|    5|\n",
      "|{TV,\"Cable TV\",In...|    5|\n",
      "|{Internet,\"Wirele...|    5|\n",
      "|{TV,\"Cable TV\",In...|    5|\n",
      "|{TV,\"Cable TV\",In...|    5|\n",
      "|{TV,\"Cable TV\",In...|    5|\n",
      "|{TV,Internet,\"Wir...|    4|\n",
      "|{TV,\"Cable TV\",In...|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Encode Amenities\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "new_df.groupBy('amenities').count().orderBy('count', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2a90cf-15fd-4518-9408-2d0e3a7fee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, split\n",
    "\n",
    "# Create a set of all possible amenities\n",
    "amenities_set = (\n",
    "    new_df\n",
    "    .select(\"amenities\")\n",
    "    .rdd\n",
    "    .flatMap(lambda row: row.amenities.replace('{', '').replace('}', '').replace('\"', '').split(','))\n",
    "    .map(lambda amenity: amenity.strip())\n",
    "    .distinct()\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f432c5-9dd8-408d-b60a-65c63ec24f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and creating dedicated columns for each amenity\n",
    "for amenity in amenities_set:\n",
    "    new_df = new_df.withColumn(amenity, col(\"amenities\").contains(amenity).cast(\"int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021e7264-83a1-4701-94c4-d97d2821c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'amenities' column\n",
    "new_df = new_df.drop(\"amenities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86347a47-2ebf-44ab-8125-e30c959ba619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_type', 'property_type', 'bedrooms', 'number_of_reviews', 'price', 'TV', 'Cable TV', 'Internet', 'Wireless Internet', 'Air Conditioning', 'Kitchen', 'Heating', 'Family/Kid Friendly', 'Washer', 'Dryer', 'Free Parking on Premises', 'Buzzer/Wireless Intercom', 'Smoke Detector', 'Carbon Monoxide Detector', 'First Aid Kit', 'Safety Card', 'Fire Extinguisher', 'Essentials', 'Pets Allowed', 'Pets live on this property', 'Dog(s)', 'Cat(s)', 'Hot Tub', 'Indoor Fireplace', 'Shampoo', 'Breakfast', '24-Hour Check-in', 'Hangers', 'Hair Dryer', 'Iron', 'Laptop Friendly Workspace', 'Suitable for Events', 'Elevator in Building', 'Wheelchair Accessible', 'Gym', '', 'Lock on Bedroom Door', 'Pool', 'Other pet(s)', 'Smoking Allowed', 'Doorman', 'Washer / Dryer']\n"
     ]
    }
   ],
   "source": [
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c625fa-b422-42a7-9148-377ffac8aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+\n",
      "|room_type      |property_type|bedrooms|number_of_reviews|price|TV |Cable TV|Internet|Wireless Internet|Air Conditioning|Kitchen|Heating|Family/Kid Friendly|Washer|Dryer|Free Parking on Premises|Buzzer/Wireless Intercom|Smoke Detector|Carbon Monoxide Detector|First Aid Kit|Safety Card|Fire Extinguisher|Essentials|Pets Allowed|Pets live on this property|Dog(s)|Cat(s)|Hot Tub|Indoor Fireplace|Shampoo|Breakfast|24-Hour Check-in|Hangers|Hair Dryer|Iron|Laptop Friendly Workspace|Suitable for Events|Elevator in Building|Wheelchair Accessible|Gym|   |Lock on Bedroom Door|Pool|Other pet(s)|Smoking Allowed|Doorman|Washer / Dryer|\n",
      "+---------------+-------------+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+\n",
      "|Entire home/apt|Apartment    |1.0     |207              |85.0 |1  |1       |1       |1                |1               |1      |1      |1                  |1     |1    |0                       |0                       |0             |0                       |0            |0          |0                |0         |0           |0                         |0     |0     |0      |0               |0      |0        |0               |0      |0         |0   |0                        |0                  |0                   |0                    |0  |1  |0                   |0   |0           |0              |0      |0             |\n",
      "+---------------+-------------+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f55edde6-7fe7-4d78-86cc-503e2b72a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|      room_type|count|\n",
      "+---------------+-----+\n",
      "|Entire home/apt| 1818|\n",
      "|   Private room|  950|\n",
      "|    Shared room|   92|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.groupBy('room_type').count().orderBy('count', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f63f0a2-0fd3-43e4-9421-b8a39530af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode room type\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# List of distinct room types\n",
    "room_types = ['Entire home/apt', 'Private room', 'Shared room']\n",
    "\n",
    "# Loop through each room type and create a new column for each\n",
    "for room_type in room_types:\n",
    "    new_df = new_df.withColumn(room_type.replace(\" \", \"_\").lower(), when(col(\"room_type\") == room_type, 1).otherwise(0))\n",
    "\n",
    "# Drop the original 'room_type' column\n",
    "new_df = new_df.drop(\"room_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24fa9bd5-6ab0-40de-8ef3-adefd4955977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['property_type', 'bedrooms', 'number_of_reviews', 'price', 'TV', 'Cable TV', 'Internet', 'Wireless Internet', 'Air Conditioning', 'Kitchen', 'Heating', 'Family/Kid Friendly', 'Washer', 'Dryer', 'Free Parking on Premises', 'Buzzer/Wireless Intercom', 'Smoke Detector', 'Carbon Monoxide Detector', 'First Aid Kit', 'Safety Card', 'Fire Extinguisher', 'Essentials', 'Pets Allowed', 'Pets live on this property', 'Dog(s)', 'Cat(s)', 'Hot Tub', 'Indoor Fireplace', 'Shampoo', 'Breakfast', '24-Hour Check-in', 'Hangers', 'Hair Dryer', 'Iron', 'Laptop Friendly Workspace', 'Suitable for Events', 'Elevator in Building', 'Wheelchair Accessible', 'Gym', '', 'Lock on Bedroom Door', 'Pool', 'Other pet(s)', 'Smoking Allowed', 'Doorman', 'Washer / Dryer', 'entire_home/apt', 'private_room', 'shared_room']\n"
     ]
    }
   ],
   "source": [
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "165e6499-74f1-4350-9b63-0e203bbe63c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+---------------+------------+-----------+\n",
      "|property_type|bedrooms|number_of_reviews|price|TV |Cable TV|Internet|Wireless Internet|Air Conditioning|Kitchen|Heating|Family/Kid Friendly|Washer|Dryer|Free Parking on Premises|Buzzer/Wireless Intercom|Smoke Detector|Carbon Monoxide Detector|First Aid Kit|Safety Card|Fire Extinguisher|Essentials|Pets Allowed|Pets live on this property|Dog(s)|Cat(s)|Hot Tub|Indoor Fireplace|Shampoo|Breakfast|24-Hour Check-in|Hangers|Hair Dryer|Iron|Laptop Friendly Workspace|Suitable for Events|Elevator in Building|Wheelchair Accessible|Gym|   |Lock on Bedroom Door|Pool|Other pet(s)|Smoking Allowed|Doorman|Washer / Dryer|entire_home/apt|private_room|shared_room|\n",
      "+-------------+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+---------------+------------+-----------+\n",
      "|Apartment    |1.0     |207              |85.0 |1  |1       |1       |1                |1               |1      |1      |1                  |1     |1    |0                       |0                       |0             |0                       |0            |0          |0                |0         |0           |0                         |0     |0     |0      |0               |0      |0        |0               |0      |0         |0   |0                        |0                  |0                   |0                    |0  |1  |0                   |0   |0           |0              |0      |0             |1              |0           |0          |\n",
      "+-------------+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+---------------+------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d997536b-ceda-4032-aa26-b57c24eed7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|  property_type|count|\n",
      "+---------------+-----+\n",
      "|          House| 1408|\n",
      "|      Apartment| 1204|\n",
      "|      Townhouse|   80|\n",
      "|    Condominium|   68|\n",
      "|Bed & Breakfast|   26|\n",
      "|           Loft|   22|\n",
      "|          Cabin|   17|\n",
      "|          Other|   13|\n",
      "|      Camper/RV|    8|\n",
      "|           Boat|    5|\n",
      "|           Tent|    4|\n",
      "|       Bungalow|    2|\n",
      "|      Treehouse|    1|\n",
      "|           Dorm|    1|\n",
      "|         Chalet|    1|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.groupBy('property_type').count().orderBy('count', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62238324-c1f0-4463-80af-04f4fbcb1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode property_type\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# List of distinct property types\n",
    "property_types = ['House', 'Apartment', 'Townhouse', 'Condominium', 'Bed & Breakfast',\n",
    "                  'Loft', 'Cabin', 'Other', 'Camper/RV', 'Boat', 'Tent', 'Bungalow',\n",
    "                  'Treehouse', 'Dorm', 'Chalet']\n",
    "\n",
    "# Loop through each property type and create a new column for each\n",
    "for property_type in property_types:\n",
    "    new_df = new_df.withColumn(property_type.replace(\" \", \"_\").lower(), when(col(\"property_type\") == property_type, 1).otherwise(0))\n",
    "\n",
    "# Drop the original 'property_type' column\n",
    "new_df = new_df.drop(\"property_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07917034-af3e-4ba2-85f0-8d9542ff4350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bedrooms', 'number_of_reviews', 'price', 'TV', 'Cable TV', 'Internet', 'Wireless Internet', 'Air Conditioning', 'Kitchen', 'Heating', 'Family/Kid Friendly', 'Washer', 'Dryer', 'Free Parking on Premises', 'Buzzer/Wireless Intercom', 'Smoke Detector', 'Carbon Monoxide Detector', 'First Aid Kit', 'Safety Card', 'Fire Extinguisher', 'Essentials', 'Pets Allowed', 'Pets live on this property', 'Dog(s)', 'Cat(s)', 'Hot Tub', 'Indoor Fireplace', 'Shampoo', 'Breakfast', '24-Hour Check-in', 'Hangers', 'Hair Dryer', 'Iron', 'Laptop Friendly Workspace', 'Suitable for Events', 'Elevator in Building', 'Wheelchair Accessible', 'Gym', '', 'Lock on Bedroom Door', 'Pool', 'Other pet(s)', 'Smoking Allowed', 'Doorman', 'Washer / Dryer', 'entire_home/apt', 'private_room', 'shared_room', 'house', 'apartment', 'townhouse', 'condominium', 'bed_&_breakfast', 'loft', 'cabin', 'other', 'camper/rv', 'boat', 'tent', 'bungalow', 'treehouse', 'dorm', 'chalet']\n"
     ]
    }
   ],
   "source": [
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70cd636-10df-4ce6-8292-0f9713ef8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+---------------+------------+-----------+-----+---------+---------+-----------+---------------+----+-----+-----+---------+----+----+--------+---------+----+------+\n",
      "|bedrooms|number_of_reviews|price|TV |Cable TV|Internet|Wireless Internet|Air Conditioning|Kitchen|Heating|Family/Kid Friendly|Washer|Dryer|Free Parking on Premises|Buzzer/Wireless Intercom|Smoke Detector|Carbon Monoxide Detector|First Aid Kit|Safety Card|Fire Extinguisher|Essentials|Pets Allowed|Pets live on this property|Dog(s)|Cat(s)|Hot Tub|Indoor Fireplace|Shampoo|Breakfast|24-Hour Check-in|Hangers|Hair Dryer|Iron|Laptop Friendly Workspace|Suitable for Events|Elevator in Building|Wheelchair Accessible|Gym|   |Lock on Bedroom Door|Pool|Other pet(s)|Smoking Allowed|Doorman|Washer / Dryer|entire_home/apt|private_room|shared_room|house|apartment|townhouse|condominium|bed_&_breakfast|loft|cabin|other|camper/rv|boat|tent|bungalow|treehouse|dorm|chalet|\n",
      "+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+---------------+------------+-----------+-----+---------+---------+-----------+---------------+----+-----+-----+---------+----+----+--------+---------+----+------+\n",
      "|1.0     |207              |85.0 |1  |1       |1       |1                |1               |1      |1      |1                  |1     |1    |0                       |0                       |0             |0                       |0            |0          |0                |0         |0           |0                         |0     |0     |0      |0               |0      |0        |0               |0      |0         |0   |0                        |0                  |0                   |0                    |0  |1  |0                   |0   |0           |0              |0      |0             |1              |0           |0          |0    |1        |0        |0          |0              |0   |0    |0    |0        |0   |0   |0       |0        |0   |0     |\n",
      "+--------+-----------------+-----+---+--------+--------+-----------------+----------------+-------+-------+-------------------+------+-----+------------------------+------------------------+--------------+------------------------+-------------+-----------+-----------------+----------+------------+--------------------------+------+------+-------+----------------+-------+---------+----------------+-------+----------+----+-------------------------+-------------------+--------------------+---------------------+---+---+--------------------+----+------------+---------------+-------+--------------+---------------+------------+-----------+-----+---------+---------+-----------+---------------+----+-----+-----+---------+----+----+--------+---------+----+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b1b0307-8254-449f-a471-4564c1b68e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df: 2860\n",
      "Number of rows in train set: 2337\n",
      "Number of rows in test set: 523\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "from pyspark.sql.functions import rand\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Split the DataFrame into train and test\n",
    "train_df, test_df = new_df.randomSplit([train_ratio, test_ratio], seed=42)\n",
    "\n",
    "# Show the number of rows in each split\n",
    "print(\"Number of rows in df:\",new_df.count())\n",
    "print(\"Number of rows in train set:\", train_df.count())\n",
    "print(\"Number of rows in test set:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a5a4db5-4543-44c9-9162-ca1e05a24d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'price' column: 2\n"
     ]
    }
   ],
   "source": [
    "# Get the index of 'price' column\n",
    "price_index = new_df.columns.index('price')\n",
    "print(\"Index of 'price' column:\", price_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19a31c38-cc80-478a-8582-f6baf9cdc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_column_index = 2\n",
    "# Define a function to extract features and label from each row\n",
    "def extract_features_label(row, price_column_index):\n",
    "    features = row[:price_column_index] + row[price_column_index+1:]  # Extract all columns except the 'price' column\n",
    "    label = row[price_column_index]  # Extract the 'price' column\n",
    "    return (features, label)\n",
    "transformed_rdd = train_df.rdd.map(lambda row: extract_features_label(row, price_column_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12807c19-b94d-46de-accc-691eb842b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1.0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 22.0)\n"
     ]
    }
   ],
   "source": [
    "print(transformed_rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5b129c2-6441-4128-8370-ca6c4aef40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 62\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_features = len(transformed_rdd.first()[0])\n",
    "print(\"num_features: \"+ str(num_features))\n",
    "weights = np.random.rand(num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c04b2d2c-b566-4ec7-a132-5a77df47d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hypothesis Function\n",
    "def hypothesis(x, weights):\n",
    "    print(x)\n",
    "    return np.dot(x, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4641c871-87fa-487a-a957-5c99b07cb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cost Function\n",
    "def cost_function(data, weights):\n",
    "    squared_errors = data.map(lambda point: (hypothesis(point[0], weights) - point[1]) ** 2)\n",
    "    return squared_errors.reduce(lambda x, y: x + y) / (2 * 2337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "642876ea-299b-4188-8a6a-83dc1fdac918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def gradient_descent(data, weights, learning_rate):\n",
    "    gradients = data.map(lambda point: np.multiply(hypothesis(point[0], weights) - point[1], point[0]))\n",
    "    gradient_sum = gradients.reduce(lambda x, y: np.add(x, y))\n",
    "    return np.subtract(weights, np.multiply(learning_rate /2337, gradient_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b66a5c99-a0ca-4f01-89a9-a14168a68ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0008\n",
    "num_iterations = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eef7a5d3-2ab6-4e76-8822-66f21c57c007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train no: 1\n",
      "Cost: 10031.591076709685\n",
      "train no: 2\n",
      "Cost: 9747.980566543001\n",
      "train no: 3\n",
      "Cost: 9547.408393751224\n",
      "train no: 4\n",
      "Cost: 9392.747568526249\n",
      "train no: 5\n",
      "Cost: 9263.793325996357\n",
      "train no: 6\n",
      "Cost: 9149.544707037727\n",
      "train no: 7\n",
      "Cost: 9044.00668615295\n",
      "train no: 8\n",
      "Cost: 8943.90704313983\n",
      "train no: 9\n",
      "Cost: 8847.454619464856\n",
      "train no: 10\n",
      "Cost: 8753.663959628993\n",
      "train no: 11\n",
      "Cost: 8661.987996220187\n",
      "train no: 12\n",
      "Cost: 8572.118272818836\n",
      "train no: 13\n",
      "Cost: 8483.876286898032\n",
      "train no: 14\n",
      "Cost: 8397.154390820011\n",
      "train no: 15\n",
      "Cost: 8311.88364637771\n",
      "train no: 16\n",
      "Cost: 8228.016338790325\n",
      "train no: 17\n",
      "Cost: 8145.516463681659\n",
      "train no: 18\n",
      "Cost: 8064.354550424378\n",
      "train no: 19\n",
      "Cost: 7984.504843977774\n",
      "train no: 20\n",
      "Cost: 7905.943769499658\n",
      "train no: 21\n",
      "Cost: 7828.649094672675\n",
      "train no: 22\n",
      "Cost: 7752.599471544213\n",
      "train no: 23\n",
      "Cost: 7677.774184817068\n",
      "train no: 24\n",
      "Cost: 7604.153012464981\n",
      "train no: 25\n",
      "Cost: 7531.716147480178\n",
      "train no: 26\n",
      "Cost: 7460.444152909116\n",
      "train no: 27\n",
      "Cost: 7390.317935032026\n",
      "train no: 28\n",
      "Cost: 7321.318726449739\n",
      "train no: 29\n",
      "Cost: 7253.42807459647\n",
      "train no: 30\n",
      "Cost: 7186.627833241511\n",
      "train no: 31\n",
      "Cost: 7120.900155653209\n",
      "train no: 32\n",
      "Cost: 7056.227488703306\n",
      "train no: 33\n",
      "Cost: 6992.592567518588\n",
      "train no: 34\n",
      "Cost: 6929.978410465056\n",
      "train no: 35\n",
      "Cost: 6868.368314347621\n",
      "train no: 36\n",
      "Cost: 6807.745849760976\n",
      "train no: 37\n",
      "Cost: 6748.094856556076\n",
      "train no: 38\n",
      "Cost: 6689.399439402193\n",
      "train no: 39\n",
      "Cost: 6631.643963433643\n",
      "train no: 40\n",
      "Cost: 6574.813049973928\n",
      "train no: 41\n",
      "Cost: 6518.891572333512\n",
      "train no: 42\n",
      "Cost: 6463.864651678365\n",
      "train no: 43\n",
      "Cost: 6409.717652967123\n",
      "train no: 44\n",
      "Cost: 6356.436180955521\n",
      "train no: 45\n",
      "Cost: 6304.006076266432\n",
      "train no: 46\n",
      "Cost: 6252.413411524636\n",
      "train no: 47\n",
      "Cost: 6201.644487554921\n",
      "train no: 48\n",
      "Cost: 6151.685829642562\n",
      "train no: 49\n",
      "Cost: 6102.524183855064\n",
      "train no: 50\n",
      "Cost: 6054.146513424273\n",
      "train no: 51\n",
      "Cost: 6006.539995187778\n",
      "train no: 52\n",
      "Cost: 5959.692016088462\n",
      "train no: 53\n",
      "Cost: 5913.590169731699\n",
      "train no: 54\n",
      "Cost: 5868.222252998714\n",
      "train no: 55\n",
      "Cost: 5823.57626271559\n",
      "train no: 56\n",
      "Cost: 5779.640392376816\n",
      "train no: 57\n",
      "Cost: 5736.403028922508\n",
      "train no: 58\n",
      "Cost: 5693.852749568441\n",
      "train no: 59\n",
      "Cost: 5651.978318688131\n",
      "train no: 60\n",
      "Cost: 5610.768684745778\n",
      "train no: 61\n",
      "Cost: 5570.21297727978\n",
      "train no: 62\n",
      "Cost: 5530.30050393538\n",
      "train no: 63\n",
      "Cost: 5491.020747546142\n",
      "train no: 64\n",
      "Cost: 5452.363363263153\n",
      "train no: 65\n",
      "Cost: 5414.318175731313\n",
      "train no: 66\n",
      "Cost: 5376.875176311869\n",
      "train no: 67\n",
      "Cost: 5340.024520350496\n",
      "train no: 68\n",
      "Cost: 5303.756524490076\n",
      "train no: 69\n",
      "Cost: 5268.061664027632\n",
      "train no: 70\n",
      "Cost: 5232.9305703144555\n",
      "train no: 71\n",
      "Cost: 5198.354028198889\n",
      "train no: 72\n",
      "Cost: 5164.322973511011\n",
      "train no: 73\n",
      "Cost: 5130.828490588576\n",
      "train no: 74\n",
      "Cost: 5097.861809843389\n",
      "train no: 75\n",
      "Cost: 5065.414305367697\n",
      "train no: 76\n",
      "Cost: 5033.477492579702\n",
      "train no: 77\n",
      "Cost: 5002.0430259076875\n",
      "train no: 78\n",
      "Cost: 4971.1026965121255\n",
      "train no: 79\n",
      "Cost: 4940.648430045046\n",
      "train no: 80\n",
      "Cost: 4910.672284446226\n",
      "train no: 81\n",
      "Cost: 4881.166447775338\n",
      "train no: 82\n",
      "Cost: 4852.123236079806\n",
      "train no: 83\n",
      "Cost: 4823.53509129744\n",
      "train no: 84\n",
      "Cost: 4795.394579193548\n",
      "train no: 85\n",
      "Cost: 4767.694387331808\n",
      "train no: 86\n",
      "Cost: 4740.427323078361\n",
      "train no: 87\n",
      "Cost: 4713.586311638689\n",
      "train no: 88\n",
      "Cost: 4687.164394126595\n",
      "train no: 89\n",
      "Cost: 4661.154725664859\n",
      "train no: 90\n",
      "Cost: 4635.550573517005\n",
      "train no: 91\n",
      "Cost: 4610.345315249704\n",
      "train no: 92\n",
      "Cost: 4585.532436925243\n",
      "train no: 93\n",
      "Cost: 4561.105531323663\n",
      "train no: 94\n",
      "Cost: 4537.058296193999\n",
      "train no: 95\n",
      "Cost: 4513.384532534225\n",
      "train no: 96\n",
      "Cost: 4490.078142899301\n",
      "train no: 97\n",
      "Cost: 4467.133129737025\n",
      "train no: 98\n",
      "Cost: 4444.543593751123\n",
      "train no: 99\n",
      "Cost: 4422.303732291141\n",
      "train no: 100\n",
      "Cost: 4400.407837768777\n",
      "train no: 101\n",
      "Cost: 4378.850296100117\n",
      "train no: 102\n",
      "Cost: 4357.625585173407\n",
      "train no: 103\n",
      "Cost: 4336.728273341959\n",
      "train no: 104\n",
      "Cost: 4316.153017941725\n",
      "train no: 105\n",
      "Cost: 4295.89456383317\n",
      "train no: 106\n",
      "Cost: 4275.9477419670375\n",
      "train no: 107\n",
      "Cost: 4256.307467973659\n",
      "train no: 108\n",
      "Cost: 4236.96874077526\n",
      "train no: 109\n",
      "Cost: 4217.92664122121\n",
      "train no: 110\n",
      "Cost: 4199.176330745412\n",
      "train no: 111\n",
      "Cost: 4180.713050045858\n",
      "train no: 112\n",
      "Cost: 4162.532117785734\n",
      "train no: 113\n",
      "Cost: 4144.628929315843\n",
      "train no: 114\n",
      "Cost: 4126.998955417969\n",
      "train no: 115\n",
      "Cost: 4109.637741068821\n",
      "train no: 116\n",
      "Cost: 4092.5409042242177\n",
      "train no: 117\n",
      "Cost: 4075.7041346232286\n",
      "train no: 118\n",
      "Cost: 4059.123192611906\n",
      "train no: 119\n",
      "Cost: 4042.7939079862476\n",
      "train no: 120\n",
      "Cost: 4026.7121788541817\n",
      "train no: 121\n",
      "Cost: 4010.8739705161624\n",
      "train no: 122\n",
      "Cost: 3995.2753143641057\n",
      "train no: 123\n",
      "Cost: 3979.912306798425\n",
      "train no: 124\n",
      "Cost: 3964.7811081627096\n",
      "train no: 125\n",
      "Cost: 3949.87794169597\n",
      "train no: 126\n",
      "Cost: 3935.1990925019722\n",
      "train no: 127\n",
      "Cost: 3920.7409065355096\n",
      "train no: 128\n",
      "Cost: 3906.4997896052582\n",
      "train no: 129\n",
      "Cost: 3892.472206392996\n",
      "train no: 130\n",
      "Cost: 3878.6546794888673\n",
      "train no: 131\n",
      "Cost: 3865.0437884424846\n",
      "train no: 132\n",
      "Cost: 3851.636168829543\n",
      "train no: 133\n",
      "Cost: 3838.428511333788\n",
      "train no: 134\n",
      "Cost: 3825.4175608439555\n",
      "train no: 135\n",
      "Cost: 3812.60011556556\n",
      "train no: 136\n",
      "Cost: 3799.9730261472414\n",
      "train no: 137\n",
      "Cost: 3787.5331948213843\n",
      "train no: 138\n",
      "Cost: 3775.2775745588624\n",
      "train no: 139\n",
      "Cost: 3763.203168237602\n",
      "train no: 140\n",
      "Cost: 3751.307027824812\n",
      "train no: 141\n",
      "Cost: 3739.5862535725646\n",
      "train no: 142\n",
      "Cost: 3728.0379932266005\n",
      "train no: 143\n",
      "Cost: 3716.659441248064\n",
      "train no: 144\n",
      "Cost: 3705.4478380480214\n",
      "train no: 145\n",
      "Cost: 3694.4004692344993\n",
      "train no: 146\n",
      "Cost: 3683.5146648718937\n",
      "train no: 147\n",
      "Cost: 3672.7877987524716\n",
      "train no: 148\n",
      "Cost: 3662.217287679845\n",
      "train no: 149\n",
      "Cost: 3651.80059076414\n",
      "train no: 150\n",
      "Cost: 3641.5352087288366\n",
      "train no: 151\n",
      "Cost: 3631.418683228776\n",
      "train no: 152\n",
      "Cost: 3621.448596179531\n",
      "train no: 153\n",
      "Cost: 3611.622569097622\n",
      "train no: 154\n",
      "Cost: 3601.9382624516593\n",
      "train no: 155\n",
      "Cost: 3592.3933750240194\n",
      "train no: 156\n",
      "Cost: 3582.9856432830647\n",
      "train no: 157\n",
      "Cost: 3573.7128407655796\n",
      "train no: 158\n",
      "Cost: 3564.572777469395\n",
      "train no: 159\n",
      "Cost: 3555.5632992558985\n",
      "train no: 160\n",
      "Cost: 3546.6822872623884\n",
      "train no: 161\n",
      "Cost: 3537.927657324036\n",
      "train no: 162\n",
      "Cost: 3529.2973594052864\n",
      "train no: 163\n",
      "Cost: 3520.7893770406854\n",
      "train no: 164\n",
      "Cost: 3512.401726784718\n",
      "train no: 165\n",
      "Cost: 3504.132457670776\n",
      "train no: 166\n",
      "Cost: 3495.979650678975\n",
      "train no: 167\n",
      "Cost: 3487.941418212618\n",
      "train no: 168\n",
      "Cost: 3480.0159035833517\n",
      "train no: 169\n",
      "Cost: 3472.201280504644\n",
      "train no: 170\n",
      "Cost: 3464.495752593677\n",
      "train no: 171\n",
      "Cost: 3456.8975528812925\n",
      "train no: 172\n",
      "Cost: 3449.4049433300506\n",
      "train no: 173\n",
      "Cost: 3442.0162143601483\n",
      "train no: 174\n",
      "Cost: 3434.7296843830945\n",
      "train no: 175\n",
      "Cost: 3427.5436993430694\n",
      "train no: 176\n",
      "Cost: 3420.456632265768\n",
      "train no: 177\n",
      "Cost: 3413.466882814629\n",
      "train no: 178\n",
      "Cost: 3406.572876854377\n",
      "train no: 179\n",
      "Cost: 3399.773066021666\n",
      "train no: 180\n",
      "Cost: 3393.065927302804\n",
      "train no: 181\n",
      "Cost: 3386.4499626183465\n",
      "train no: 182\n",
      "Cost: 3379.923698414566\n",
      "train no: 183\n",
      "Cost: 3373.485685261548\n",
      "train no: 184\n",
      "Cost: 3367.1344974579115\n",
      "train no: 185\n",
      "Cost: 3360.868732641997\n",
      "train no: 186\n",
      "Cost: 3354.6870114094386\n",
      "train no: 187\n",
      "Cost: 3348.5879769369585\n",
      "train no: 188\n",
      "Cost: 3342.5702946123974\n",
      "train no: 189\n",
      "Cost: 3336.6326516707472\n",
      "train no: 190\n",
      "Cost: 3330.7737568361636\n",
      "train no: 191\n",
      "Cost: 3324.992339969871\n",
      "train no: 192\n",
      "Cost: 3319.287151723806\n",
      "train no: 193\n",
      "Cost: 3313.65696319994\n",
      "train no: 194\n",
      "Cost: 3308.100565615201\n",
      "train no: 195\n",
      "Cost: 3302.6167699718935\n",
      "train no: 196\n",
      "Cost: 3297.2044067334577\n",
      "train no: 197\n",
      "Cost: 3291.862325505635\n",
      "train no: 198\n",
      "Cost: 3286.5893947227896\n",
      "train no: 199\n",
      "Cost: 3281.384501339386\n",
      "train no: 200\n",
      "Cost: 3276.246550526528\n",
      "train no: 201\n",
      "Cost: 3271.1744653735022\n",
      "train no: 202\n",
      "Cost: 3266.167186594109\n",
      "train no: 203\n",
      "Cost: 3261.2236722379716\n",
      "train no: 204\n",
      "Cost: 3256.342897406393\n",
      "train no: 205\n",
      "Cost: 3251.523853973008\n",
      "train no: 206\n",
      "Cost: 3246.765550308954\n",
      "train no: 207\n",
      "Cost: 3242.0670110125293\n",
      "train no: 208\n",
      "Cost: 3237.427276643346\n",
      "train no: 209\n",
      "Cost: 3232.8454034607603\n",
      "train no: 210\n",
      "Cost: 3228.3204631666517\n",
      "train no: 211\n",
      "Cost: 3223.8515426523923\n",
      "train no: 212\n",
      "Cost: 3219.437743749939\n",
      "train no: 213\n",
      "Cost: 3215.0781829870552\n",
      "train no: 214\n",
      "Cost: 3210.7719913465157\n",
      "train no: 215\n",
      "Cost: 3206.5183140292306\n",
      "train no: 216\n",
      "Cost: 3202.3163102213243\n",
      "train no: 217\n",
      "Cost: 3198.1651528649486\n",
      "train no: 218\n",
      "Cost: 3194.0640284329006\n",
      "train no: 219\n",
      "Cost: 3190.0121367069355\n",
      "train no: 220\n",
      "Cost: 3186.0086905596663\n",
      "train no: 221\n",
      "Cost: 3182.052915740112\n",
      "train no: 222\n",
      "Cost: 3178.1440506627\n",
      "train no: 223\n",
      "Cost: 3174.281346199718\n",
      "train no: 224\n",
      "Cost: 3170.4640654772447\n",
      "train no: 225\n",
      "Cost: 3166.6914836743254\n",
      "train no: 226\n",
      "Cost: 3162.96288782552\n",
      "train no: 227\n",
      "Cost: 3159.2775766266323\n",
      "train no: 228\n",
      "Cost: 3155.634860243639\n",
      "train no: 229\n",
      "Cost: 3152.034060124797\n",
      "train no: 230\n",
      "Cost: 3148.474508815709\n",
      "train no: 231\n",
      "Cost: 3144.9555497775873\n",
      "train no: 232\n",
      "Cost: 3141.4765372083234\n",
      "train no: 233\n",
      "Cost: 3138.0368358666346\n",
      "train no: 234\n",
      "Cost: 3134.6358208989927\n",
      "train no: 235\n",
      "Cost: 3131.272877669445\n",
      "train no: 236\n",
      "Cost: 3127.9474015921805\n",
      "train no: 237\n",
      "Cost: 3124.6587979668916\n",
      "train no: 238\n",
      "Cost: 3121.406481816797\n",
      "train no: 239\n",
      "Cost: 3118.1898777293172\n",
      "train no: 240\n",
      "Cost: 3115.008419699376\n",
      "train no: 241\n",
      "Cost: 3111.8615509752835\n",
      "train no: 242\n",
      "Cost: 3108.748723907092\n",
      "train no: 243\n",
      "Cost: 3105.6693997975003\n",
      "train no: 244\n",
      "Cost: 3102.623048755168\n",
      "train no: 245\n",
      "Cost: 3099.609149550422\n",
      "train no: 246\n",
      "Cost: 3096.6271894733413\n",
      "train no: 247\n",
      "Cost: 3093.676664194212\n",
      "train no: 248\n",
      "Cost: 3090.7570776261673\n",
      "train no: 249\n",
      "Cost: 3087.8679417901735\n",
      "train no: 250\n",
      "Cost: 3085.008776682176\n",
      "train no: 251\n",
      "Cost: 3082.179110142461\n",
      "train no: 252\n",
      "Cost: 3079.3784777270967\n",
      "train no: 253\n",
      "Cost: 3076.6064225815626\n",
      "train no: 254\n",
      "Cost: 3073.8624953163812\n",
      "train no: 255\n",
      "Cost: 3071.1462538848023\n",
      "train no: 256\n",
      "Cost: 3068.457263462543\n",
      "train no: 257\n",
      "Cost: 3065.7950963294224\n",
      "train no: 258\n",
      "Cost: 3063.1593317529837\n",
      "train no: 259\n",
      "Cost: 3060.5495558740054\n",
      "train no: 260\n",
      "Cost: 3057.965361593913\n",
      "train no: 261\n",
      "Cost: 3055.4063484639832\n",
      "train no: 262\n",
      "Cost: 3052.8721225764425\n",
      "train no: 263\n",
      "Cost: 3050.3622964572733\n",
      "train no: 264\n",
      "Cost: 3047.876488960789\n",
      "train no: 265\n",
      "Cost: 3045.414325166025\n",
      "train no: 266\n",
      "Cost: 3042.975436274687\n",
      "train no: 267\n",
      "Cost: 3040.5594595108805\n",
      "train no: 268\n",
      "Cost: 3038.166038022446\n",
      "train no: 269\n",
      "Cost: 3035.7948207838967\n",
      "train no: 270\n",
      "Cost: 3033.445462500973\n",
      "train no: 271\n",
      "Cost: 3031.1176235167345\n",
      "train no: 272\n",
      "Cost: 3028.810969719239\n",
      "train no: 273\n",
      "Cost: 3026.5251724506497\n",
      "train no: 274\n",
      "Cost: 3024.2599084179233\n",
      "train no: 275\n",
      "Cost: 3022.0148596049175\n",
      "train no: 276\n",
      "Cost: 3019.7897131859213\n",
      "train no: 277\n",
      "Cost: 3017.584161440647\n",
      "train no: 278\n",
      "Cost: 3015.397901670574\n",
      "train no: 279\n",
      "Cost: 3013.230636116692\n",
      "train no: 280\n",
      "Cost: 3011.082071878575\n",
      "train no: 281\n",
      "Cost: 3008.9519208347974\n",
      "train no: 282\n",
      "Cost: 3006.839899564628\n",
      "train no: 283\n",
      "Cost: 3004.7457292710424\n",
      "train no: 284\n",
      "Cost: 3002.66913570497\n",
      "train no: 285\n",
      "Cost: 3000.6098490907716\n",
      "train no: 286\n",
      "Cost: 2998.5676040530016\n",
      "train no: 287\n",
      "Cost: 2996.5421395442895\n",
      "train no: 288\n",
      "Cost: 2994.5331987744385\n",
      "train no: 289\n",
      "Cost: 2992.540529140721\n",
      "train no: 290\n",
      "Cost: 2990.563882159234\n",
      "train no: 291\n",
      "Cost: 2988.6030133974764\n",
      "train no: 292\n",
      "Cost: 2986.657682407943\n",
      "train no: 293\n",
      "Cost: 2984.7276526628734\n",
      "train no: 294\n",
      "Cost: 2982.812691490016\n",
      "train no: 295\n",
      "Cost: 2980.912570009514\n",
      "train no: 296\n",
      "Cost: 2979.02706307173\n",
      "train no: 297\n",
      "Cost: 2977.1559491961784\n",
      "train no: 298\n",
      "Cost: 2975.299010511421\n",
      "train no: 299\n",
      "Cost: 2973.456032695921\n",
      "train no: 300\n",
      "Cost: 2971.626804919935\n",
      "train no: 301\n",
      "Cost: 2969.8111197882818\n",
      "train no: 302\n",
      "Cost: 2968.008773284099\n",
      "train no: 303\n",
      "Cost: 2966.219564713503\n",
      "train no: 304\n",
      "Cost: 2964.443296651176\n",
      "train no: 305\n",
      "Cost: 2962.6797748867866\n",
      "train no: 306\n",
      "Cost: 2960.9288083723723\n",
      "train no: 307\n",
      "Cost: 2959.1902091705015\n",
      "train no: 308\n",
      "Cost: 2957.46379240337\n",
      "train no: 309\n",
      "Cost: 2955.7493762026397\n",
      "train no: 310\n",
      "Cost: 2954.0467816601836\n",
      "train no: 311\n",
      "Cost: 2952.355832779573\n",
      "train no: 312\n",
      "Cost: 2950.676356428401\n",
      "train no: 313\n",
      "Cost: 2949.0081822913726\n",
      "train no: 314\n",
      "Cost: 2947.351142824144\n",
      "train no: 315\n",
      "Cost: 2945.7050732079756\n",
      "train no: 316\n",
      "Cost: 2944.069811305052\n",
      "train no: 317\n",
      "Cost: 2942.4451976145997\n",
      "train no: 318\n",
      "Cost: 2940.8310752296834\n",
      "train no: 319\n",
      "Cost: 2939.2272897947246\n",
      "train no: 320\n",
      "Cost: 2937.63368946372\n",
      "train no: 321\n",
      "Cost: 2936.050124859135\n",
      "train no: 322\n",
      "Cost: 2934.47644903149\n",
      "train no: 323\n",
      "Cost: 2932.9125174195624\n",
      "train no: 324\n",
      "Cost: 2931.358187811312\n",
      "train no: 325\n",
      "Cost: 2929.8133203053726\n",
      "train no: 326\n",
      "Cost: 2928.277777273243\n",
      "train no: 327\n",
      "Cost: 2926.7514233220463\n",
      "train no: 328\n",
      "Cost: 2925.2341252578985\n",
      "train no: 329\n",
      "Cost: 2923.7257520499343\n",
      "train no: 330\n",
      "Cost: 2922.226174794865\n",
      "train no: 331\n",
      "Cost: 2920.7352666821303\n",
      "train no: 332\n",
      "Cost: 2919.252902959643\n",
      "train no: 333\n",
      "Cost: 2917.7789609000583\n",
      "train no: 334\n",
      "Cost: 2916.3133197676434\n",
      "train no: 335\n",
      "Cost: 2914.8558607856503\n",
      "train no: 336\n",
      "Cost: 2913.4064671042233\n",
      "train no: 337\n",
      "Cost: 2911.965023768859\n",
      "train no: 338\n",
      "Cost: 2910.5314176893717\n",
      "train no: 339\n",
      "Cost: 2909.1055376093746\n",
      "train no: 340\n",
      "Cost: 2907.687274076216\n",
      "train no: 341\n",
      "Cost: 2906.276519411471\n",
      "train no: 342\n",
      "Cost: 2904.8731676819016\n",
      "train no: 343\n",
      "Cost: 2903.477114670852\n",
      "train no: 344\n",
      "Cost: 2902.0882578501355\n",
      "train no: 345\n",
      "Cost: 2900.706496352448\n",
      "train no: 346\n",
      "Cost: 2899.331730944086\n",
      "train no: 347\n",
      "Cost: 2897.963863998272\n",
      "train no: 348\n",
      "Cost: 2896.6027994688043\n",
      "train no: 349\n",
      "Cost: 2895.2484428641847\n",
      "train no: 350\n",
      "Cost: 2893.900701222179\n",
      "train no: 351\n",
      "Cost: 2892.5594830847563\n",
      "train no: 352\n",
      "Cost: 2891.224698473485\n",
      "train no: 353\n",
      "Cost: 2889.8962588652935\n",
      "train no: 354\n",
      "Cost: 2888.574077168633\n",
      "train no: 355\n",
      "Cost: 2887.2580677000788\n",
      "train no: 356\n",
      "Cost: 2885.94814616122\n",
      "train no: 357\n",
      "Cost: 2884.6442296160453\n",
      "train no: 358\n",
      "Cost: 2883.3462364686166\n",
      "train no: 359\n",
      "Cost: 2882.0540864410946\n",
      "train no: 360\n",
      "Cost: 2880.7677005522232\n",
      "train no: 361\n",
      "Cost: 2879.4870010960485\n",
      "train no: 362\n",
      "Cost: 2878.211911621087\n",
      "train no: 363\n",
      "Cost: 2876.9423569097603\n",
      "train no: 364\n",
      "Cost: 2875.6782629582176\n",
      "train no: 365\n",
      "Cost: 2874.41955695643\n",
      "train no: 366\n",
      "Cost: 2873.1661672687137\n",
      "train no: 367\n",
      "Cost: 2871.9180234144383\n",
      "train no: 368\n",
      "Cost: 2870.675056049174\n",
      "train no: 369\n",
      "Cost: 2869.4371969460535\n",
      "train no: 370\n",
      "Cost: 2868.2043789775125\n",
      "train no: 371\n",
      "Cost: 2866.976536097285\n",
      "train no: 372\n",
      "Cost: 2865.7536033226947\n",
      "train no: 373\n",
      "Cost: 2864.5355167172474\n",
      "train no: 374\n",
      "Cost: 2863.32221337355\n",
      "train no: 375\n",
      "Cost: 2862.1136313963975\n",
      "train no: 376\n",
      "Cost: 2860.909709886281\n",
      "train no: 377\n",
      "Cost: 2859.71038892302\n",
      "train no: 378\n",
      "Cost: 2858.5156095498046\n",
      "train no: 379\n",
      "Cost: 2857.325313757391\n",
      "train no: 380\n",
      "Cost: 2856.139444468593\n",
      "train no: 381\n",
      "Cost: 2854.957945523039\n",
      "train no: 382\n",
      "Cost: 2853.780761662173\n",
      "train no: 383\n",
      "Cost: 2852.6078385145006\n",
      "train no: 384\n",
      "Cost: 2851.439122581055\n",
      "train no: 385\n",
      "Cost: 2850.2745612211447\n",
      "train no: 386\n",
      "Cost: 2849.1141026382847\n",
      "train no: 387\n",
      "Cost: 2847.9576958663984\n",
      "train no: 388\n",
      "Cost: 2846.805290756242\n",
      "train no: 389\n",
      "Cost: 2845.6568379620053\n",
      "train no: 390\n",
      "Cost: 2844.5122889282106\n",
      "train no: 391\n",
      "Cost: 2843.37159587674\n",
      "train no: 392\n",
      "Cost: 2842.2347117941513\n",
      "train no: 393\n",
      "Cost: 2841.1015904191545\n",
      "train no: 394\n",
      "Cost: 2839.9721862302954\n",
      "train no: 395\n",
      "Cost: 2838.8464544338794\n",
      "train no: 396\n",
      "Cost: 2837.724350952041\n",
      "train no: 397\n",
      "Cost: 2836.6058324110504\n",
      "train no: 398\n",
      "Cost: 2835.490856129797\n",
      "train no: 399\n",
      "Cost: 2834.379380108435\n",
      "train no: 400\n",
      "Cost: 2833.271363017272\n",
      "train no: 401\n",
      "Cost: 2832.1667641858016\n",
      "train no: 402\n",
      "Cost: 2831.065543591902\n",
      "train no: 403\n",
      "Cost: 2829.9676618512444\n",
      "train no: 404\n",
      "Cost: 2828.8730802068785\n",
      "train no: 405\n",
      "Cost: 2827.7817605189343\n",
      "train no: 406\n",
      "Cost: 2826.693665254579\n",
      "train no: 407\n",
      "Cost: 2825.608757478039\n",
      "train no: 408\n",
      "Cost: 2824.5270008408775\n",
      "train no: 409\n",
      "Cost: 2823.448359572358\n",
      "train no: 410\n",
      "Cost: 2822.372798470027\n",
      "train no: 411\n",
      "Cost: 2821.3002828904173\n",
      "train no: 412\n",
      "Cost: 2820.2307787398795\n",
      "train no: 413\n",
      "Cost: 2819.164252465622\n",
      "train no: 414\n",
      "Cost: 2818.1006710468555\n",
      "train no: 415\n",
      "Cost: 2817.040001986125\n",
      "train no: 416\n",
      "Cost: 2815.982213300684\n",
      "train no: 417\n",
      "Cost: 2814.9272735141644\n",
      "train no: 418\n",
      "Cost: 2813.875151648239\n",
      "train no: 419\n",
      "Cost: 2812.8258172145097\n",
      "train no: 420\n",
      "Cost: 2811.779240206481\n",
      "train no: 421\n",
      "Cost: 2810.735391091707\n",
      "train no: 422\n",
      "Cost: 2809.694240804013\n",
      "train no: 423\n",
      "Cost: 2808.6557607359023\n",
      "train no: 424\n",
      "Cost: 2807.6199227310535\n",
      "train no: 425\n",
      "Cost: 2806.5866990769205\n",
      "train no: 426\n",
      "Cost: 2805.5560624975324\n",
      "train no: 427\n",
      "Cost: 2804.527986146305\n",
      "train no: 428\n",
      "Cost: 2803.5024435990586\n",
      "train no: 429\n",
      "Cost: 2802.4794088471026\n",
      "train no: 430\n",
      "Cost: 2801.4588562904673\n",
      "train no: 431\n",
      "Cost: 2800.4407607311873\n",
      "train no: 432\n",
      "Cost: 2799.425097366763\n",
      "train no: 433\n",
      "Cost: 2798.411841783704\n",
      "train no: 434\n",
      "Cost: 2797.400969951156\n",
      "train no: 435\n",
      "Cost: 2796.3924582146537\n",
      "train no: 436\n",
      "Cost: 2795.386283289986\n",
      "train no: 437\n",
      "Cost: 2794.3824222571343\n",
      "train no: 438\n",
      "Cost: 2793.3808525543327\n",
      "train no: 439\n",
      "Cost: 2792.381551972203\n",
      "train no: 440\n",
      "Cost: 2791.3844986480335\n",
      "train no: 441\n",
      "Cost: 2790.389671060082\n",
      "train no: 442\n",
      "Cost: 2789.397048022019\n",
      "train no: 443\n",
      "Cost: 2788.406608677454\n",
      "train no: 444\n",
      "Cost: 2787.418332494557\n",
      "train no: 445\n",
      "Cost: 2786.4321992607447\n",
      "train no: 446\n",
      "Cost: 2785.4481890774846\n",
      "train no: 447\n",
      "Cost: 2784.4662823551316\n",
      "train no: 448\n",
      "Cost: 2783.4864598079425\n",
      "train no: 449\n",
      "Cost: 2782.508702449074\n",
      "train no: 450\n",
      "Cost: 2781.532991585712\n",
      "train no: 451\n",
      "Cost: 2780.5593088142896\n",
      "train no: 452\n",
      "Cost: 2779.587636015734\n",
      "train no: 453\n",
      "Cost: 2778.6179553508605\n",
      "train no: 454\n",
      "Cost: 2777.6502492557884\n",
      "train no: 455\n",
      "Cost: 2776.6845004374377\n",
      "train no: 456\n",
      "Cost: 2775.7206918691313\n",
      "train no: 457\n",
      "Cost: 2774.7588067862457\n",
      "train no: 458\n",
      "Cost: 2773.798828681921\n",
      "train no: 459\n",
      "Cost: 2772.840741302871\n",
      "train no: 460\n",
      "Cost: 2771.8845286452347\n",
      "train no: 461\n",
      "Cost: 2770.930174950529\n",
      "train no: 462\n",
      "Cost: 2769.9776647016283\n",
      "train no: 463\n",
      "Cost: 2769.0269826188323\n",
      "train no: 464\n",
      "Cost: 2768.078113655986\n",
      "train no: 465\n",
      "Cost: 2767.1310429967093\n",
      "train no: 466\n",
      "Cost: 2766.1857560505982\n",
      "train no: 467\n",
      "Cost: 2765.242238449579\n",
      "train no: 468\n",
      "Cost: 2764.3004760442795\n",
      "train no: 469\n",
      "Cost: 2763.3604549004363\n",
      "train no: 470\n",
      "Cost: 2762.4221612954184\n",
      "train no: 471\n",
      "Cost: 2761.485581714775\n",
      "train no: 472\n",
      "Cost: 2760.5507028488278\n",
      "train no: 473\n",
      "Cost: 2759.6175115893557\n",
      "train no: 474\n",
      "Cost: 2758.68599502629\n",
      "train no: 475\n",
      "Cost: 2757.7561404445014\n",
      "train no: 476\n",
      "Cost: 2756.8279353206117\n",
      "train no: 477\n",
      "Cost: 2755.901367319897\n",
      "train no: 478\n",
      "Cost: 2754.9764242931815\n",
      "train no: 479\n",
      "Cost: 2754.0530942738333\n",
      "train no: 480\n",
      "Cost: 2753.131365474803\n",
      "train no: 481\n",
      "Cost: 2752.2112262856717\n",
      "train no: 482\n",
      "Cost: 2751.2926652697915\n",
      "train no: 483\n",
      "Cost: 2750.375671161469\n",
      "train no: 484\n",
      "Cost: 2749.4602328631554\n",
      "train no: 485\n",
      "Cost: 2748.5463394427293\n",
      "train no: 486\n",
      "Cost: 2747.633980130798\n",
      "train no: 487\n",
      "Cost: 2746.723144318065\n",
      "train no: 488\n",
      "Cost: 2745.8138215526815\n",
      "train no: 489\n",
      "Cost: 2744.906001537737\n",
      "train no: 490\n",
      "Cost: 2743.99967412872\n",
      "train no: 491\n",
      "Cost: 2743.0948293310125\n",
      "train no: 492\n",
      "Cost: 2742.1914572975074\n",
      "train no: 493\n",
      "Cost: 2741.2895483261555\n",
      "train no: 494\n",
      "Cost: 2740.3890928576234\n",
      "train no: 495\n",
      "Cost: 2739.490081473004\n",
      "train no: 496\n",
      "Cost: 2738.5925048914983\n",
      "train no: 497\n",
      "Cost: 2737.696353968182\n",
      "train no: 498\n",
      "Cost: 2736.8016196917915\n",
      "train no: 499\n",
      "Cost: 2735.9082931825665\n",
      "train no: 500\n",
      "Cost: 2735.0163656901036\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_no=1\n",
    "cost_values=[]\n",
    "for _ in range(num_iterations):\n",
    "    print(\"train no: \"+str(train_no))\n",
    "    weights = gradient_descent(transformed_rdd, weights, learning_rate)\n",
    "    cost = cost_function(transformed_rdd, weights)\n",
    "    cost_values.append(cost)\n",
    "    train_no+=1\n",
    "    print(\"Cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee0e02e5-8194-4a5b-867b-1857e0f2e543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test convergence\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming cost_values is a list containing cost values at each epoch\n",
    "cost_values = [9835.27887626617, 9799.87676723162, 9772.990264272146, 9751.332654211788, 9732.889819803166, 9716.42748976651, 9701.18928194726, 9686.711664367487, 9672.710563483419, 9659.011877802215, 9645.508896673498, 9632.13620655341, 9618.853700780848, 9605.636780779096, 9592.470351358672]\n",
    "\n",
    "# Plotting the cost values\n",
    "plt.plot(range(1, len(cost_values) + 1), cost_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Training Cost Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8b0b16b4-8279-423b-b948-ac533b22c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rdd = test_df.rdd.map(lambda row: extract_features_label(row, price_column_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d95711b8-0f5f-4485-a26f-c7810b8a920d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  93.0120089946551\n",
      "label:  30.0\n",
      "======================================\n",
      "prediction:  78.88572994172472\n",
      "label:  39.0\n",
      "======================================\n",
      "prediction:  104.95108419914624\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  99.85021571740413\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  93.6927728975473\n",
      "label:  49.0\n",
      "======================================\n",
      "prediction:  105.07751938592978\n",
      "label:  50.0\n",
      "======================================\n",
      "prediction:  85.88378260728538\n",
      "label:  53.0\n",
      "======================================\n",
      "prediction:  87.55587901115061\n",
      "label:  59.0\n",
      "======================================\n",
      "prediction:  97.06778577612482\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  136.0027503189158\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  77.78754910204172\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  145.9201397446696\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  126.90289551050103\n",
      "label:  72.0\n",
      "======================================\n",
      "prediction:  130.3538776619048\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  94.92910620587935\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  110.24694023792253\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  130.32646283799082\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  96.77882734620421\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  128.011072921397\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  131.20232796921994\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  118.18251198049703\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  148.5992750667774\n",
      "label:  135.0\n",
      "======================================\n",
      "prediction:  126.22014739401746\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  137.88663553196457\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  141.87802881083522\n",
      "label:  205.0\n",
      "======================================\n",
      "prediction:  123.8919131358618\n",
      "label:  550.0\n",
      "======================================\n",
      "prediction:  98.37681274973295\n",
      "label:  35.0\n",
      "======================================\n",
      "prediction:  125.35773121736406\n",
      "label:  39.0\n",
      "======================================\n",
      "prediction:  100.5954550073086\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  114.43212309380932\n",
      "label:  50.0\n",
      "======================================\n",
      "prediction:  136.27181070357128\n",
      "label:  51.0\n",
      "======================================\n",
      "prediction:  154.15437543632322\n",
      "label:  66.0\n",
      "======================================\n",
      "prediction:  142.10908737425777\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  135.6120214981623\n",
      "label:  78.0\n",
      "======================================\n",
      "prediction:  94.70923317149551\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  148.09217145443793\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  110.40210972434818\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  155.09902802858835\n",
      "label:  139.0\n",
      "======================================\n",
      "prediction:  101.80455599922581\n",
      "label:  148.0\n",
      "======================================\n",
      "prediction:  96.7699277785782\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  113.24733181690333\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  142.0160675953569\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  96.80040654427472\n",
      "label:  280.0\n",
      "======================================\n",
      "prediction:  108.41809420170691\n",
      "label:  29.0\n",
      "======================================\n",
      "prediction:  141.58201221047042\n",
      "label:  30.0\n",
      "======================================\n",
      "prediction:  106.86104938842726\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  113.85588113369047\n",
      "label:  41.0\n",
      "======================================\n",
      "prediction:  94.86940475022422\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  122.26899966179913\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  101.44812959178293\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  153.75937008500074\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  142.499942431303\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  118.62074546805069\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  133.887867360384\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  129.10809898796938\n",
      "label:  129.0\n",
      "======================================\n",
      "prediction:  158.26635704370702\n",
      "label:  139.0\n",
      "======================================\n",
      "prediction:  85.35793326350003\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  107.84555532571375\n",
      "label:  45.0\n",
      "======================================\n",
      "prediction:  99.47938224836034\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  124.13371701655885\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  121.99168794821412\n",
      "label:  74.0\n",
      "======================================\n",
      "prediction:  125.32045812042962\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  114.10014485914621\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  104.70105006826603\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  116.3487951289632\n",
      "label:  105.0\n",
      "======================================\n",
      "prediction:  128.82892921187033\n",
      "label:  109.0\n",
      "======================================\n",
      "prediction:  124.1242796613086\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  150.15659798331475\n",
      "label:  185.0\n",
      "======================================\n",
      "prediction:  118.7239184102381\n",
      "label:  199.0\n",
      "======================================\n",
      "prediction:  138.395864153397\n",
      "label:  212.0\n",
      "======================================\n",
      "prediction:  135.56946266175245\n",
      "label:  249.0\n",
      "======================================\n",
      "prediction:  118.07197154466223\n",
      "label:  45.0\n",
      "======================================\n",
      "prediction:  85.00429046975003\n",
      "label:  53.0\n",
      "======================================\n",
      "prediction:  120.18804256815059\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  124.84643148948602\n",
      "label:  82.0\n",
      "======================================\n",
      "prediction:  111.71132184065848\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  147.17186584675977\n",
      "label:  88.0\n",
      "======================================\n",
      "prediction:  130.19970383070742\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  132.82578253382454\n",
      "label:  98.0\n",
      "======================================\n",
      "prediction:  131.96604204267064\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  135.68740743958003\n",
      "label:  105.0\n",
      "======================================\n",
      "prediction:  139.54712500839045\n",
      "label:  109.0\n",
      "======================================\n",
      "prediction:  94.0242497528662\n",
      "label:  160.0\n",
      "======================================\n",
      "prediction:  107.5936062989944\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  121.18759304248931\n",
      "label:  54.0\n",
      "======================================\n",
      "prediction:  80.86193705928373\n",
      "label:  66.0\n",
      "======================================\n",
      "prediction:  159.44464832964925\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  116.9708424289277\n",
      "label:  94.0\n",
      "======================================\n",
      "prediction:  115.30268042674284\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  139.35763894249538\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  120.91481143563429\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  117.3519401700782\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  95.26682022159709\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  83.42759743200094\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  133.81742621467836\n",
      "label:  165.0\n",
      "======================================\n",
      "prediction:  123.86953835285027\n",
      "label:  35.0\n",
      "======================================\n",
      "prediction:  94.09839465787812\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  123.90728799968164\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  123.16192032769409\n",
      "label:  78.0\n",
      "======================================\n",
      "prediction:  98.81834785387197\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  113.70062902333115\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  131.02867342707825\n",
      "label:  91.0\n",
      "======================================\n",
      "prediction:  83.7293993804011\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  134.37896417891838\n",
      "label:  119.0\n",
      "======================================\n",
      "prediction:  134.2685916477526\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  141.9780484392792\n",
      "label:  140.0\n",
      "======================================\n",
      "prediction:  103.89712113358006\n",
      "label:  28.0\n",
      "======================================\n",
      "prediction:  134.2502882721563\n",
      "label:  74.0\n",
      "======================================\n",
      "prediction:  132.80726257106255\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  115.22800392304632\n",
      "label:  84.0\n",
      "======================================\n",
      "prediction:  107.50877311196608\n",
      "label:  135.0\n",
      "======================================\n",
      "prediction:  136.4397825978644\n",
      "label:  140.0\n",
      "======================================\n",
      "prediction:  103.67724809919622\n",
      "label:  35.0\n",
      "======================================\n",
      "prediction:  113.92600986377363\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  116.69877750553256\n",
      "label:  66.0\n",
      "======================================\n",
      "prediction:  99.42972655586553\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  117.4308993274948\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  103.24163678604364\n",
      "label:  82.0\n",
      "======================================\n",
      "prediction:  125.50214693830034\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  124.84856178194265\n",
      "label:  145.0\n",
      "======================================\n",
      "prediction:  90.76552960899583\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  128.18689476704193\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  115.02192039488853\n",
      "label:  49.0\n",
      "======================================\n",
      "prediction:  102.44911295360032\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  83.5274213909936\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  119.45060673178027\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  96.3721542718349\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  121.8388800121739\n",
      "label:  126.0\n",
      "======================================\n",
      "prediction:  133.82184813849372\n",
      "label:  155.0\n",
      "======================================\n",
      "prediction:  102.7962240989397\n",
      "label:  43.0\n",
      "======================================\n",
      "prediction:  121.84183508531343\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  120.25548699494948\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  154.5518745356775\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  121.79309440530508\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  115.11843081079101\n",
      "label:  122.0\n",
      "======================================\n",
      "prediction:  103.32235521539205\n",
      "label:  132.0\n",
      "======================================\n",
      "prediction:  92.975504264394\n",
      "label:  135.0\n",
      "======================================\n",
      "prediction:  122.25517376177105\n",
      "label:  276.0\n",
      "======================================\n",
      "prediction:  156.13520933434114\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  82.1371809962115\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  93.94226984512167\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  141.7732300535587\n",
      "label:  105.0\n",
      "======================================\n",
      "prediction:  111.96726084949958\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  136.3062637843042\n",
      "label:  122.0\n",
      "======================================\n",
      "prediction:  117.32086252830365\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  126.4092323203086\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  81.66718874448121\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  117.81489342974267\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  135.5745894462634\n",
      "label:  97.0\n",
      "======================================\n",
      "prediction:  89.43047039262211\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  97.0682770276364\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  124.02042725520646\n",
      "label:  199.0\n",
      "======================================\n",
      "prediction:  93.93825628135181\n",
      "label:  41.0\n",
      "======================================\n",
      "prediction:  96.99186627041422\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  84.51351931642128\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  144.83410050898468\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  141.7307495606714\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  129.40895713736745\n",
      "label:  126.0\n",
      "======================================\n",
      "prediction:  102.56533926585824\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  109.83561780020207\n",
      "label:  56.0\n",
      "======================================\n",
      "prediction:  122.77559489840269\n",
      "label:  57.0\n",
      "======================================\n",
      "prediction:  93.95002315163502\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  121.90332162697379\n",
      "label:  79.0\n",
      "======================================\n",
      "prediction:  118.57311700899851\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  129.17203089356966\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  143.37864504769303\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  103.93068612643224\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  87.21016979568907\n",
      "label:  93.0\n",
      "======================================\n",
      "prediction:  59.372095132009974\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  152.50679662516274\n",
      "label:  145.0\n",
      "======================================\n",
      "prediction:  99.34552058152335\n",
      "label:  155.0\n",
      "======================================\n",
      "prediction:  102.51901011229609\n",
      "label:  195.0\n",
      "======================================\n",
      "prediction:  105.52942880531117\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  117.67945622303397\n",
      "label:  59.0\n",
      "======================================\n",
      "prediction:  136.89951805770107\n",
      "label:  63.0\n",
      "======================================\n",
      "prediction:  105.19601985010621\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  95.52644407128741\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  120.34049416671571\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  106.1778911312819\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  148.05918595524872\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  126.21031673112829\n",
      "label:  180.0\n",
      "======================================\n",
      "prediction:  131.79023183416365\n",
      "label:  50.0\n",
      "======================================\n",
      "prediction:  130.30952530301792\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  134.9592595484538\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  112.72518838465469\n",
      "label:  119.0\n",
      "======================================\n",
      "prediction:  105.53964680891815\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  92.46313417240447\n",
      "label:  33.0\n",
      "======================================\n",
      "prediction:  73.33571091469008\n",
      "label:  42.0\n",
      "======================================\n",
      "prediction:  93.21689457300324\n",
      "label:  45.0\n",
      "======================================\n",
      "prediction:  103.48992229190281\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  92.94761729232727\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  123.8385375883073\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  106.38426329627647\n",
      "label:  78.0\n",
      "======================================\n",
      "prediction:  126.85250036191393\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  145.2935712827656\n",
      "label:  109.0\n",
      "======================================\n",
      "prediction:  123.20868726073552\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  122.25121409239753\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  106.23852384893061\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  120.92983281608517\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  142.92270320070995\n",
      "label:  149.0\n",
      "======================================\n",
      "prediction:  122.21942853668939\n",
      "label:  165.0\n",
      "======================================\n",
      "prediction:  106.31039032501947\n",
      "label:  29.0\n",
      "======================================\n",
      "prediction:  93.62285280026325\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  123.6909278055828\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  96.18128673260274\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  106.09051729063563\n",
      "label:  31.0\n",
      "======================================\n",
      "prediction:  87.0533649171773\n",
      "label:  50.0\n",
      "======================================\n",
      "prediction:  103.72411492764172\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  130.50516857539907\n",
      "label:  139.0\n",
      "======================================\n",
      "prediction:  122.94825893528875\n",
      "label:  188.0\n",
      "======================================\n",
      "prediction:  133.05430547821103\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  102.68496333669088\n",
      "label:  68.0\n",
      "======================================\n",
      "prediction:  90.99703980551753\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  131.25461305410298\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  124.47691271559394\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  100.55682071368645\n",
      "label:  104.0\n",
      "======================================\n",
      "prediction:  138.13124809434092\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  130.5824546015011\n",
      "label:  128.0\n",
      "======================================\n",
      "prediction:  103.00321745376547\n",
      "label:  35.0\n",
      "======================================\n",
      "prediction:  96.58467773043652\n",
      "label:  39.0\n",
      "======================================\n",
      "prediction:  108.16229610711088\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  116.62345938644233\n",
      "label:  47.0\n",
      "======================================\n",
      "prediction:  109.20665028972883\n",
      "label:  119.0\n",
      "======================================\n",
      "prediction:  109.41532696798546\n",
      "label:  140.0\n",
      "======================================\n",
      "prediction:  111.37702657058486\n",
      "label:  58.0\n",
      "======================================\n",
      "prediction:  98.64153727001434\n",
      "label:  29.0\n",
      "======================================\n",
      "prediction:  115.55423041124449\n",
      "label:  149.0\n",
      "======================================\n",
      "prediction:  105.77852792069669\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  107.90559916894549\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  72.34452325245627\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  134.59593478298248\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  100.73091479827954\n",
      "label:  38.0\n",
      "======================================\n",
      "prediction:  75.20037883571374\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  85.47780838791712\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  118.81689420276365\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  105.92189007012803\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  56.25484742416616\n",
      "label:  92.0\n",
      "======================================\n",
      "prediction:  119.02542392539517\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  130.2877519799743\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  122.39114836702754\n",
      "label:  129.0\n",
      "======================================\n",
      "prediction:  79.10769120954396\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  109.45971344794158\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  116.34137780260548\n",
      "label:  126.0\n",
      "======================================\n",
      "prediction:  112.50144229192443\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  112.49746042363098\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  116.93177197648251\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  130.94920434986392\n",
      "label:  149.0\n",
      "======================================\n",
      "prediction:  123.52925377840612\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  118.90874180700666\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  93.18300711648368\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  80.50804300165441\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  120.82396156763203\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  89.72152357707483\n",
      "label:  68.0\n",
      "======================================\n",
      "prediction:  138.80690545221802\n",
      "label:  135.0\n",
      "======================================\n",
      "prediction:  135.24027593972\n",
      "label:  159.0\n",
      "======================================\n",
      "prediction:  141.19896536524982\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  94.06653579580369\n",
      "label:  49.0\n",
      "======================================\n",
      "prediction:  111.27483868259287\n",
      "label:  50.0\n",
      "======================================\n",
      "prediction:  122.41051990145579\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  127.68934928245827\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  140.57307351322837\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  72.25678807775263\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  145.69384344567501\n",
      "label:  139.0\n",
      "======================================\n",
      "prediction:  120.96259187571057\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  116.65955970337569\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  114.76219040526938\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  121.44642247355183\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  86.29487430489061\n",
      "label:  169.0\n",
      "======================================\n",
      "prediction:  123.54016072016847\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  121.81316646398514\n",
      "label:  145.0\n",
      "======================================\n",
      "prediction:  125.22821575018692\n",
      "label:  169.0\n",
      "======================================\n",
      "prediction:  129.77088997576357\n",
      "label:  300.0\n",
      "======================================\n",
      "prediction:  66.32079153134003\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  120.2566037246725\n",
      "label:  87.0\n",
      "======================================\n",
      "prediction:  134.01188963969238\n",
      "label:  105.0\n",
      "======================================\n",
      "prediction:  120.12920171704036\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  132.21135924003312\n",
      "label:  37.0\n",
      "======================================\n",
      "prediction:  125.9512095392235\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  106.17836618222375\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  100.06034415602704\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  111.18169398439017\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  96.4369468088458\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  121.46742023914263\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  76.35815211837499\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  127.33272988154025\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  114.36141988264497\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  149.97424867278616\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  138.16585971792497\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  110.56520712716723\n",
      "label:  84.0\n",
      "======================================\n",
      "prediction:  118.92723301639133\n",
      "label:  111.0\n",
      "======================================\n",
      "prediction:  110.64073680461178\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  131.74658494757443\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  128.1093094405984\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  117.3519648364409\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  90.96293276272277\n",
      "label:  88.0\n",
      "======================================\n",
      "prediction:  99.8350477403396\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  88.54179113817369\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  126.62224489481504\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  94.05630391287602\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  81.28618670216576\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  87.1130133440078\n",
      "label:  66.0\n",
      "======================================\n",
      "prediction:  113.44760566236081\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  109.12205621024367\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  129.83637498302312\n",
      "label:  120.0\n",
      "======================================\n",
      "prediction:  127.56688538824955\n",
      "label:  36.0\n",
      "======================================\n",
      "prediction:  49.665108418562156\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  89.93177723493825\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  130.16043906603602\n",
      "label:  155.0\n",
      "======================================\n",
      "prediction:  103.90204385232198\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  105.9172874179902\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  99.50301504536391\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  99.95463524198604\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  88.16776485566598\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  59.09454980180222\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  120.53979926285768\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  113.23910631101309\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  92.14022553786978\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  51.26497319519596\n",
      "label:  45.0\n",
      "======================================\n",
      "prediction:  97.03779271138296\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  121.7222157325822\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  88.9184770711918\n",
      "label:  45.0\n",
      "======================================\n",
      "prediction:  96.49745263961759\n",
      "label:  58.0\n",
      "======================================\n",
      "prediction:  83.05267362485466\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  79.63865028482734\n",
      "label:  58.0\n",
      "======================================\n",
      "prediction:  125.66089292059486\n",
      "label:  92.0\n",
      "======================================\n",
      "prediction:  83.0965471207209\n",
      "label:  48.0\n",
      "======================================\n",
      "prediction:  85.13235000810425\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  100.31770814091252\n",
      "label:  72.0\n",
      "======================================\n",
      "prediction:  67.29163878697774\n",
      "label:  59.0\n",
      "======================================\n",
      "prediction:  108.05978690417864\n",
      "label:  145.0\n",
      "======================================\n",
      "prediction:  73.93438023802354\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  79.5782396347492\n",
      "label:  69.0\n",
      "======================================\n",
      "prediction:  84.84742364607737\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  96.64623371765526\n",
      "label:  51.0\n",
      "======================================\n",
      "prediction:  108.60073274174752\n",
      "label:  40.0\n",
      "======================================\n",
      "prediction:  101.56970313537059\n",
      "label:  169.0\n",
      "======================================\n",
      "prediction:  85.81616416618138\n",
      "label:  35.0\n",
      "======================================\n",
      "prediction:  109.41491113463609\n",
      "label:  122.0\n",
      "======================================\n",
      "prediction:  109.34617950304303\n",
      "label:  90.0\n",
      "======================================\n",
      "prediction:  96.6626738917258\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  81.73940168889851\n",
      "label:  225.0\n",
      "======================================\n",
      "prediction:  101.69616144167013\n",
      "label:  77.0\n",
      "======================================\n",
      "prediction:  58.29472889480585\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  72.03925892732656\n",
      "label:  70.0\n",
      "======================================\n",
      "prediction:  87.04028886790255\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  103.400859592657\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  96.0735105309055\n",
      "label:  60.0\n",
      "======================================\n",
      "prediction:  97.87015219893036\n",
      "label:  65.0\n",
      "======================================\n",
      "prediction:  104.88747448026596\n",
      "label:  97.0\n",
      "======================================\n",
      "prediction:  42.44595216856285\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  73.64848094556599\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  105.3089874366737\n",
      "label:  82.0\n",
      "======================================\n",
      "prediction:  76.37653308407475\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  67.05276155713405\n",
      "label:  55.0\n",
      "======================================\n",
      "prediction:  71.27203900105971\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  89.09167417305815\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  40.602720628392845\n",
      "label:  58.0\n",
      "======================================\n",
      "prediction:  43.411954334591975\n",
      "label:  79.0\n",
      "======================================\n",
      "prediction:  18.563283530305632\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  19.62380436672003\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  158.76151326332828\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  174.56338243989202\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  158.55666884081168\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  151.32743867470163\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  159.64761502167633\n",
      "label:  500.0\n",
      "======================================\n",
      "prediction:  175.20871915135345\n",
      "label:  98.0\n",
      "======================================\n",
      "prediction:  146.6652517806882\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  169.43516525719457\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  160.66285078287513\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  155.36243052298255\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  73.76765876726525\n",
      "label:  140.0\n",
      "======================================\n",
      "prediction:  169.6370969139308\n",
      "label:  166.0\n",
      "======================================\n",
      "prediction:  174.226922060661\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  153.8526824616789\n",
      "label:  130.0\n",
      "======================================\n",
      "prediction:  164.5606190891272\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  158.14164467916837\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  175.06793372215932\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  151.02363998697035\n",
      "label:  98.0\n",
      "======================================\n",
      "prediction:  160.26405214628306\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  173.11289134500677\n",
      "label:  149.0\n",
      "======================================\n",
      "prediction:  123.22092610595999\n",
      "label:  152.0\n",
      "======================================\n",
      "prediction:  155.78369785896385\n",
      "label:  180.0\n",
      "======================================\n",
      "prediction:  182.83325490936474\n",
      "label:  239.0\n",
      "======================================\n",
      "prediction:  174.3846577927806\n",
      "label:  154.0\n",
      "======================================\n",
      "prediction:  154.99253129523314\n",
      "label:  160.0\n",
      "======================================\n",
      "prediction:  139.93216949010917\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  152.85659904796432\n",
      "label:  190.0\n",
      "======================================\n",
      "prediction:  180.73878876895944\n",
      "label:  193.0\n",
      "======================================\n",
      "prediction:  160.13596362375662\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  155.08963102626686\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  146.15953274799617\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  164.89468303468598\n",
      "label:  229.0\n",
      "======================================\n",
      "prediction:  168.8628028026201\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  171.11496181326868\n",
      "label:  189.0\n",
      "======================================\n",
      "prediction:  174.58568770353608\n",
      "label:  495.0\n",
      "======================================\n",
      "prediction:  181.3607633441206\n",
      "label:  245.0\n",
      "======================================\n",
      "prediction:  148.41539866367629\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  148.25534519422507\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  172.85767177405742\n",
      "label:  220.0\n",
      "======================================\n",
      "prediction:  181.87395370680392\n",
      "label:  280.0\n",
      "======================================\n",
      "prediction:  158.6532997844387\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  155.61303745022818\n",
      "label:  240.0\n",
      "======================================\n",
      "prediction:  181.2511087420054\n",
      "label:  85.0\n",
      "======================================\n",
      "prediction:  127.02697401405558\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  160.4259012363744\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  161.61113722374785\n",
      "label:  215.0\n",
      "======================================\n",
      "prediction:  152.63526053584982\n",
      "label:  185.0\n",
      "======================================\n",
      "prediction:  172.68069734191772\n",
      "label:  245.0\n",
      "======================================\n",
      "prediction:  155.7768201655447\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  180.3489793829093\n",
      "label:  128.0\n",
      "======================================\n",
      "prediction:  162.69844084870547\n",
      "label:  155.0\n",
      "======================================\n",
      "prediction:  154.12368141338865\n",
      "label:  158.0\n",
      "======================================\n",
      "prediction:  165.3543096652908\n",
      "label:  169.0\n",
      "======================================\n",
      "prediction:  131.79522189716928\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  173.046970131969\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  166.8875233752378\n",
      "label:  240.0\n",
      "======================================\n",
      "prediction:  173.1528507802513\n",
      "label:  225.0\n",
      "======================================\n",
      "prediction:  138.30009552678257\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  162.96358628056936\n",
      "label:  109.0\n",
      "======================================\n",
      "prediction:  183.12890250707432\n",
      "label:  143.0\n",
      "======================================\n",
      "prediction:  163.2990524126963\n",
      "label:  225.0\n",
      "======================================\n",
      "prediction:  180.71871029802426\n",
      "label:  275.0\n",
      "======================================\n",
      "prediction:  173.6764928816381\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  153.42204005867043\n",
      "label:  105.0\n",
      "======================================\n",
      "prediction:  153.8687420519019\n",
      "label:  107.0\n",
      "======================================\n",
      "prediction:  173.7443807372143\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  165.67605251146105\n",
      "label:  160.0\n",
      "======================================\n",
      "prediction:  145.38773650274644\n",
      "label:  195.0\n",
      "======================================\n",
      "prediction:  139.0318799014894\n",
      "label:  195.0\n",
      "======================================\n",
      "prediction:  155.49118693509206\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  158.0925031465683\n",
      "label:  165.0\n",
      "======================================\n",
      "prediction:  184.59298178639443\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  169.82437538266802\n",
      "label:  299.0\n",
      "======================================\n",
      "prediction:  161.94701956105797\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  161.34269741224446\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  148.31725797279285\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  156.1870952518952\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  184.98365618099885\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  131.4687536261707\n",
      "label:  190.0\n",
      "======================================\n",
      "prediction:  152.3055430199185\n",
      "label:  557.0\n",
      "======================================\n",
      "prediction:  177.89754266801518\n",
      "label:  92.0\n",
      "======================================\n",
      "prediction:  129.27073047143378\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  142.40832455486628\n",
      "label:  220.0\n",
      "======================================\n",
      "prediction:  149.27331681073917\n",
      "label:  165.0\n",
      "======================================\n",
      "prediction:  158.68119090589727\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  160.98613845149754\n",
      "label:  147.0\n",
      "======================================\n",
      "prediction:  155.54672568433787\n",
      "label:  180.0\n",
      "======================================\n",
      "prediction:  153.100538220769\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  162.5242128719937\n",
      "label:  140.0\n",
      "======================================\n",
      "prediction:  150.41498166138624\n",
      "label:  75.0\n",
      "======================================\n",
      "prediction:  137.110945860744\n",
      "label:  108.0\n",
      "======================================\n",
      "prediction:  134.33692495097756\n",
      "label:  125.0\n",
      "======================================\n",
      "prediction:  135.5036040967106\n",
      "label:  80.0\n",
      "======================================\n",
      "prediction:  150.2266843366736\n",
      "label:  105.0\n",
      "======================================\n",
      "prediction:  118.09754298007681\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  190.08350995565758\n",
      "label:  140.0\n",
      "======================================\n",
      "prediction:  190.1050740335587\n",
      "label:  197.0\n",
      "======================================\n",
      "prediction:  191.42053423145987\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  187.00764099962535\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  167.5583879677971\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  189.37032607611502\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  195.2653764983389\n",
      "label:  359.0\n",
      "======================================\n",
      "prediction:  190.7914981428184\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  185.43783522385274\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  188.28369083002406\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  206.52212468112296\n",
      "label:  175.0\n",
      "======================================\n",
      "prediction:  194.2623266829309\n",
      "label:  285.0\n",
      "======================================\n",
      "prediction:  170.80054997070584\n",
      "label:  95.0\n",
      "======================================\n",
      "prediction:  194.44052477368285\n",
      "label:  110.0\n",
      "======================================\n",
      "prediction:  199.21602111197873\n",
      "label:  127.0\n",
      "======================================\n",
      "prediction:  199.8873022739848\n",
      "label:  180.0\n",
      "======================================\n",
      "prediction:  196.21166421632012\n",
      "label:  190.0\n",
      "======================================\n",
      "prediction:  205.6833514127941\n",
      "label:  225.0\n",
      "======================================\n",
      "prediction:  179.2997533953012\n",
      "label:  295.0\n",
      "======================================\n",
      "prediction:  203.56390585519887\n",
      "label:  114.0\n",
      "======================================\n",
      "prediction:  180.52426748663677\n",
      "label:  210.0\n",
      "======================================\n",
      "prediction:  186.93745143026763\n",
      "label:  220.0\n",
      "======================================\n",
      "prediction:  193.98873215062164\n",
      "label:  400.0\n",
      "======================================\n",
      "prediction:  193.85904037276822\n",
      "label:  400.0\n",
      "======================================\n",
      "prediction:  199.81863061936588\n",
      "label:  112.0\n",
      "======================================\n",
      "prediction:  181.02346561056993\n",
      "label:  170.0\n",
      "======================================\n",
      "prediction:  188.564172853866\n",
      "label:  299.0\n",
      "======================================\n",
      "prediction:  185.43203032330177\n",
      "label:  348.0\n",
      "======================================\n",
      "prediction:  204.08053982776633\n",
      "label:  950.0\n",
      "======================================\n",
      "prediction:  189.71138159129862\n",
      "label:  100.0\n",
      "======================================\n",
      "prediction:  179.2932220404398\n",
      "label:  210.0\n",
      "======================================\n",
      "prediction:  195.0061354946269\n",
      "label:  235.0\n",
      "======================================\n",
      "prediction:  178.77551333798837\n",
      "label:  270.0\n",
      "======================================\n",
      "prediction:  163.773705141923\n",
      "label:  139.0\n",
      "======================================\n",
      "prediction:  174.4650363776563\n",
      "label:  199.0\n",
      "======================================\n",
      "prediction:  183.9391645353927\n",
      "label:  199.0\n",
      "======================================\n",
      "prediction:  182.48132703313672\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  211.71618229539405\n",
      "label:  295.0\n",
      "======================================\n",
      "prediction:  198.5724873425116\n",
      "label:  450.0\n",
      "======================================\n",
      "prediction:  205.69645367183804\n",
      "label:  600.0\n",
      "======================================\n",
      "prediction:  210.31052205206078\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  199.1681718244278\n",
      "label:  220.0\n",
      "======================================\n",
      "prediction:  178.2423750984218\n",
      "label:  98.0\n",
      "======================================\n",
      "prediction:  191.77547555549845\n",
      "label:  335.0\n",
      "======================================\n",
      "prediction:  183.01456584315315\n",
      "label:  375.0\n",
      "======================================\n",
      "prediction:  202.20199497660423\n",
      "label:  375.0\n",
      "======================================\n",
      "prediction:  185.59439322153253\n",
      "label:  150.0\n",
      "======================================\n",
      "prediction:  170.49076940590922\n",
      "label:  295.0\n",
      "======================================\n",
      "prediction:  169.10867943816626\n",
      "label:  300.0\n",
      "======================================\n",
      "prediction:  195.5606178547521\n",
      "label:  300.0\n",
      "======================================\n",
      "prediction:  179.94298766709431\n",
      "label:  245.0\n",
      "======================================\n",
      "prediction:  185.46028504460185\n",
      "label:  89.0\n",
      "======================================\n",
      "prediction:  175.79974907867725\n",
      "label:  99.0\n",
      "======================================\n",
      "prediction:  178.17214698057538\n",
      "label:  115.0\n",
      "======================================\n",
      "prediction:  201.58923895659638\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  223.66744634849005\n",
      "label:  244.0\n",
      "======================================\n",
      "prediction:  192.81313702104973\n",
      "label:  350.0\n",
      "======================================\n",
      "prediction:  228.9813968949694\n",
      "label:  335.0\n",
      "======================================\n",
      "prediction:  225.58999574818455\n",
      "label:  450.0\n",
      "======================================\n",
      "prediction:  222.44772825803597\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  219.98833472133475\n",
      "label:  435.0\n",
      "======================================\n",
      "prediction:  216.67262725583277\n",
      "label:  300.0\n",
      "======================================\n",
      "prediction:  211.56822651846107\n",
      "label:  200.0\n",
      "======================================\n",
      "prediction:  233.01673200008844\n",
      "label:  250.0\n",
      "======================================\n",
      "prediction:  248.93083225777528\n",
      "label:  700.0\n",
      "======================================\n",
      "prediction:  282.6665315956801\n",
      "label:  550.0\n",
      "======================================\n",
      "prediction:  245.98825702861689\n",
      "label:  490.0\n",
      "======================================\n",
      "prediction:  286.0826278782325\n",
      "label:  375.0\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# # Define a function to make predictions\n",
    "# def predict(features, weights):\n",
    "#     return np.dot(features, weights)\n",
    "\n",
    "# # Make predictions on a new set of features\n",
    "# def make_predictions(data, weights):\n",
    "#     predictions = data.map(lambda point: (point[0], predict(point[0], weights)))\n",
    "#     return predictions\n",
    "\n",
    "# # Use the trained weights to make predictions on the test set\n",
    "# predictions = make_predictions(test_rdd, weights)\n",
    "\n",
    "# # Optional: Collect the predictions as a list\n",
    "# predictions_list = predictions.collect()\n",
    "\n",
    "# # # Print the predictions (if needed)\n",
    "# # for features, prediction in predictions_list:\n",
    "# #     # print(\"Features:\", features)\n",
    "# #     print(\"Predicted Price:\", prediction)\n",
    "# Calculate predictions for the test dataset\n",
    "predictions = test_rdd.map(lambda point: (hypothesis(point[0], weights), point[1]))\n",
    "predictions_list = predictions.collect()\n",
    "for prediction,label in predictions_list:\n",
    "    print(\"prediction: \",prediction)\n",
    "    print(\"label: \",label)\n",
    "    print(\"======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "064b7b7d-06b7-436c-84b0-e79038e1e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 49.228371743973454\n",
      "Mean Squared Error (MSE): 6209.293319936464\n",
      "Root Mean Squared Error (RMSE): 78.79906928344055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to calculate Mean Absolute Error (MAE)\n",
    "def calculate_mae(predictions):\n",
    "    mae = np.mean([abs(pred[0] - pred[1]) for pred in predictions])\n",
    "    return mae\n",
    "\n",
    "# Define a function to calculate Mean Squared Error (MSE)\n",
    "def calculate_mse(predictions):\n",
    "    mse = np.mean([(pred[0] - pred[1]) ** 2 for pred in predictions])\n",
    "    return mse\n",
    "\n",
    "# Define a function to calculate Root Mean Squared Error (RMSE)\n",
    "def calculate_rmse(predictions):\n",
    "    mse = calculate_mse(predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = calculate_mae(predictions_list)\n",
    "mse = calculate_mse(predictions_list)\n",
    "rmse = calculate_rmse(predictions_list)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbad788-2aa2-4d91-b67b-d9df67a7bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to calculate Mean Absolute Error (MAE)\n",
    "# def calculate_mae(predictions, actual_values):\n",
    "#     mae = predictions.map(lambda pred: abs(pred[1] - actual_values[pred[0]]))\n",
    "#     return mae.mean()\n",
    "\n",
    "# # Define a function to calculate Mean Squared Error (MSE)\n",
    "# def calculate_mse(predictions, actual_values):\n",
    "#     mse = predictions.map(lambda pred: (pred[1] - actual_values[pred[0]]) ** 2)\n",
    "#     return mse.mean()\n",
    "\n",
    "# # Define a function to calculate Root Mean Squared Error (RMSE)\n",
    "# def calculate_rmse(predictions, actual_values):\n",
    "#     mse = calculate_mse(predictions, actual_values)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     return rmse\n",
    "\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# mae = calculate_mae(predictions, actual_values_dict)\n",
    "# mse = calculate_mse(predictions, actual_values_dict)\n",
    "# rmse = calculate_rmse(predictions, actual_values_dict)\n",
    "\n",
    "# print(\"Mean Absolute Error (MAE):\", mae)\n",
    "# print(\"Mean Squared Error (MSE):\", mse)\n",
    "# print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a681861a-8001-4ef8-9eec-43e95b1b8603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical columns: ['name', 'summary', 'space', 'description', 'instant_bookable', 'neighborhood_overview', 'neighbourhood_cleansed', 'host_name', 'host_response_time', 'street', 'property_type', 'room_type', 'amenities', 'cancellation_policy']\n"
     ]
    }
   ],
   "source": [
    "# # Get column names\n",
    "# column_names = df.columns\n",
    "# # # Identify categorical columns (replace with your actual list)\n",
    "# categorical_cols = []  \n",
    "# idx=0\n",
    "# for feat in df.rdd.collect()[0]:\n",
    "#     # print(feat)\n",
    "#     if isinstance(feat, str):\n",
    "#         categorical_cols.append(column_names[idx])   \n",
    "#     idx+=1\n",
    "# print(\"categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463e80c9-e188-45ab-b428-61b74aca31c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d08f806-47a9-4f94-8d78-5c9d53d9b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "# from pyspark.sql.functions import col\n",
    "# def parse_data(df):\n",
    "#     \"\"\"\n",
    "#     Parse the given DataFrame by applying StringIndexer and OneHotEncoder to categorical columns.\n",
    "\n",
    "#     Args:\n",
    "#         df (DataFrame): Input DataFrame.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: Parsed DataFrame with features and label columns.\n",
    "#     \"\"\"\n",
    "#     # Apply StringIndexer and OneHotEncoder to categorical columns\n",
    "#     for col_name in categorical_cols:\n",
    "#         string_indexer = StringIndexer(inputCol=col_name, outputCol=col_name + \"_index\")\n",
    "#         df = string_indexer.fit(df).transform(df)\n",
    "#         encoder = OneHotEncoder(inputCols=[col_name + \"_index\"], outputCols=[col_name + \"_encoded\"])\n",
    "#         df = encoder.fit(df).transform(df)\n",
    "\n",
    "#     # Select only the features and label columns\n",
    "#     selected_cols = [col(col_name + \"_encoded\") for col_name in categorical_cols] + \\\n",
    "#                     [col(col_name) for col_name in column_names if col_name not in categorical_cols]\n",
    "\n",
    "#     # print(\"df label\",df.columns[-1])\n",
    "#     # Select the label column as the last column\n",
    "#     # selected_cols.append(col(df.columns[-1]))\n",
    "\n",
    "#     # Create a new DataFrame with selected columns\n",
    "#     parsed_data = df.select(selected_cols)\n",
    "   \n",
    "\n",
    "\n",
    "#     return parsed_data,selected_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8bce797-34bf-4fb4-9726-3cac3a82a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+-------------------+------------------------+-----------------------------+------------------------------+------------------+--------------------------+------------------+---------------------+-----------------+------------------+---------------------------+------+-------------------+------------------+-------+----------+-------+--------------------+------------+---------+--------+----+-----------------+-----------------+-----+\n",
      "|name_encoded       |summary_encoded   |space_encoded     |description_encoded|instant_bookable_encoded|neighborhood_overview_encoded|neighbourhood_cleansed_encoded|host_name_encoded |host_response_time_encoded|street_encoded    |property_type_encoded|room_type_encoded|amenities_encoded |cancellation_policy_encoded|id    |longitude          |latitude          |host_id|host_since|zipcode|review_scores_rating|accommodates|bathrooms|bedrooms|beds|reviews_per_month|number_of_reviews|price|\n",
      "+-------------------+------------------+------------------+-------------------+------------------------+-----------------------------+------------------------------+------------------+--------------------------+------------------+---------------------+-----------------+------------------+---------------------------+------+-------------------+------------------+-------+----------+-------+--------------------+------------+---------+--------+----+-----------------+-----------------+-----+\n",
      "|(2847,[2448],[1.0])|(2587,[0],[1.0])  |(2477,[867],[1.0])|(2805,[1287],[1.0])|(1,[0],[1.0])           |(1983,[0],[1.0])             |(86,[18],[1.0])               |(1195,[240],[1.0])|(4,[1],[1.0])             |(1244,[443],[1.0])|(14,[1],[1.0])       |(2,[0],[1.0])    |(2468,[48],[1.0]) |(2,[1],[1.0])              |241032|-122.37102519997764|47.636289038357184|956883 |2011-08-11|98119  |95.0                |4           |1.0      |1.0     |1.0 |4.07             |207              |85.0 |\n",
      "|(2847,[517],[1.0]) |(2587,[533],[1.0])|(2477,[311],[1.0])|(2805,[552],[1.0]) |(1,[0],[1.0])           |(1983,[78],[1.0])            |(86,[18],[1.0])               |(1195,[37],[1.0]) |(4,[0],[1.0])             |(1244,[47],[1.0]) |(14,[1],[1.0])       |(2,[0],[1.0])    |(2468,[191],[1.0])|(2,[0],[1.0])              |953595|-122.36566646439582|47.63912312136253 |5177328|2013-02-21|98119  |96.0                |4           |1.0      |1.0     |1.0 |1.48             |43               |150.0|\n",
      "+-------------------+------------------+------------------+-------------------+------------------------+-----------------------------+------------------------------+------------------+--------------------------+------------------+---------------------+-----------------+------------------+---------------------------+------+-------------------+------------------+-------+----------+-------+--------------------+------------+---------+--------+----+-----------------+-----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "['name_encoded', 'summary_encoded', 'space_encoded', 'description_encoded', 'instant_bookable_encoded', 'neighborhood_overview_encoded', 'neighbourhood_cleansed_encoded', 'host_name_encoded', 'host_response_time_encoded', 'street_encoded', 'property_type_encoded', 'room_type_encoded', 'amenities_encoded', 'cancellation_policy_encoded', 'id', 'longitude', 'latitude', 'host_id', 'host_since', 'zipcode', 'review_scores_rating', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'reviews_per_month', 'number_of_reviews', 'price']\n"
     ]
    }
   ],
   "source": [
    "# parsed_data,new_columns = parse_data(df)\n",
    "# parsed_data.show(2, truncate=False)\n",
    "# print(parsed_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f15c017-1d0e-4c37-b620-80436665c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_to_features_label(row):\n",
    "#     # Get all columns except the last one as features\n",
    "#     features = tuple(row[:-1])\n",
    "#     # Get the last column as label\n",
    "#     label = row[-1]\n",
    "#     return (features, label)\n",
    "\n",
    "# # Assuming your RDD contains rows where each row is a list or tuple representing a record\n",
    "# features_label_rdd = parsed_data.rdd.map(map_to_features_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de474666-c338-4371-b511-57bf8ab9db25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((SparseVector(2847, {2448: 1.0}), SparseVector(2587, {0: 1.0}), SparseVector(2477, {867: 1.0}), SparseVector(2805, {1287: 1.0}), SparseVector(1, {0: 1.0}), SparseVector(1983, {0: 1.0}), SparseVector(86, {18: 1.0}), SparseVector(1195, {240: 1.0}), SparseVector(4, {1: 1.0}), SparseVector(1244, {443: 1.0}), SparseVector(14, {1: 1.0}), SparseVector(2, {0: 1.0}), SparseVector(2468, {48: 1.0}), SparseVector(2, {1: 1.0}), 241032, -122.37102519997764, 47.636289038357184, 956883, datetime.date(2011, 8, 11), 98119, 95.0, 4, 1.0, 1.0, 1.0, 4.07, 207), 85.0)\n"
     ]
    }
   ],
   "source": [
    "# print(features_label_rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444c443d-9664-45c2-a6bf-771df28eed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 27\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_features = len(features_label_rdd.first()[0])\n",
    "print(\"num_features: \"+ str(num_features))\n",
    "weights = np.random.rand(num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600dc7ad-5850-4ea5-a2a9-8b5114e27b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [0.87046856 0.23976199 0.66213714 0.63516609 0.06668356 0.71060495\n",
      " 0.03810719 0.66848876 0.77808885 0.22765066 0.59193383 0.07102096\n",
      " 0.18270704 0.90036144 0.84343172 0.55622916 0.26375011 0.2763589\n",
      " 0.19233865 0.27871359 0.43218039 0.80314704 0.75291542 0.52609523\n",
      " 0.71738962 0.84796832 0.11538921]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights: \",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aceb1f2c-afb9-4419-a588-3e171cc5d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Hypothesis Function\n",
    "def hypothesis(x, weights):\n",
    "#     x_dense = x.toArray()\n",
    "\n",
    "#     print(x)\n",
    "#     return np.dot(x, weights)\n",
    "    # Convert each SparseVector to dense array and compute dot product individually\n",
    "    dot_products = [np.dot(vec.toArray(), weights) for vec in x]\n",
    "    # Sum the dot products to get the overall hypothesis value\n",
    "    return np.sum(dot_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa8f7857-4096-43ea-86f0-1af3733ae981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cost Function\n",
    "def cost_function(data, weights):\n",
    "    squared_errors = data.map(lambda point: (hypothesis(point[0], weights) - point[1]) ** 2)\n",
    "    return squared_errors.reduce(lambda x, y: x + y) / (2 * 3818)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39e3c95-8ab6-4ee2-8134-fb1b3e9a9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def gradient_descent(data, weights, learning_rate):\n",
    "    gradients = data.map(lambda point: np.multiply(hypothesis(point[0], weights) - point[1], point[0]))\n",
    "    print(gradients)\n",
    "    gradient_sum = gradients.reduce(lambda x, y: np.add(x, y))\n",
    "    return np.subtract(weights, np.multiply(learning_rate / 3818, gradient_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a6194f9-2113-4721-8628-1f2c0973c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "644dfd3b-7e93-4d58-b082-f17cc342d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train no: 1\n",
      "PythonRDD[250] at RDD at PythonRDD.scala:53\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 93.0 failed 1 times, most recent failure: Lost task 0.0 in stage 93.0 (TID 65) (ebc14d848522 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n              ^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_171/326524951.py\", line 3, in <lambda>\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in hypothesis\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in <listcomp>\n  File \"<__array_function__ internals>\", line 200, in dot\nValueError: shapes (2847,) and (27,) not aligned: 2847 (dim 0) != 27 (dim 0)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1046)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n              ^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_171/326524951.py\", line 3, in <lambda>\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in hypothesis\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in <listcomp>\n  File \"<__array_function__ internals>\", line 200, in dot\nValueError: shapes (2847,) and (27,) not aligned: 2847 (dim 0) != 27 (dim 0)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1046)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain no: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(train_no))\n\u001b[0;32m----> 5\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_label_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights after train no:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(train_no) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ,is :\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(weights))\n\u001b[1;32m      7\u001b[0m     cost \u001b[38;5;241m=\u001b[39m cost_function(features_label_rdd, weights)\n",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(data, weights, learning_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m gradients \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m point: np\u001b[38;5;241m.\u001b[39mmultiply(hypothesis(point[\u001b[38;5;241m0\u001b[39m], weights) \u001b[38;5;241m-\u001b[39m point[\u001b[38;5;241m1\u001b[39m], point[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(gradients)\n\u001b[0;32m----> 5\u001b[0m gradient_sum \u001b[38;5;241m=\u001b[39m \u001b[43mgradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msubtract(weights, np\u001b[38;5;241m.\u001b[39mmultiply(learning_rate \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3818\u001b[39m, gradient_sum))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/rdd.py:1924\u001b[0m, in \u001b[0;36mRDD.reduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m reduce(f, iterator, initial)\n\u001b[0;32m-> 1924\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vals:\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduce(f, vals)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/rdd.py:1833\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1833\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 93.0 failed 1 times, most recent failure: Lost task 0.0 in stage 93.0 (TID 65) (ebc14d848522 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n              ^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_171/326524951.py\", line 3, in <lambda>\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in hypothesis\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in <listcomp>\n  File \"<__array_function__ internals>\", line 200, in dot\nValueError: shapes (2847,) and (27,) not aligned: 2847 (dim 0) != 27 (dim 0)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1046)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n              ^^^^^^^^^^^^^^\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_171/326524951.py\", line 3, in <lambda>\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in hypothesis\n  File \"/tmp/ipykernel_171/1833759935.py\", line 8, in <listcomp>\n  File \"<__array_function__ internals>\", line 200, in dot\nValueError: shapes (2847,) and (27,) not aligned: 2847 (dim 0) != 27 (dim 0)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1046)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_no=1\n",
    "for _ in range(num_iterations):\n",
    "    print(\"train no: \"+str(train_no))\n",
    "    weights = gradient_descent(features_label_rdd, weights, learning_rate)\n",
    "    print(\"weights after train no:\"+str(train_no) +\" ,is :\"+str(weights))\n",
    "    cost = cost_function(features_label_rdd, weights)\n",
    "    train_no+=1\n",
    "    print(\"Cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c190e0-baef-4cdc-8fb0-b221f79b5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "# from pyspark.sql import Row\n",
    "\n",
    "# def parse_data_rdd(row, string_indexers, encoders):\n",
    "#     # Apply StringIndexer and OneHotEncoder to categorical columns\n",
    "#     for col_name, indexer, encoder in zip(categorical_cols, string_indexers, encoders):\n",
    "#         row[col_name + \"_index\"] = indexer.transform([row[col_name]])[0]\n",
    "#         row[col_name + \"_encoded\"] = encoder.transform([row[col_name + \"_index\"]])[0]\n",
    "    \n",
    "#     # Select only the features and label columns\n",
    "#     selected_cols = [row[col_name + \"_encoded\"] for col_name in categorical_cols] + \\\n",
    "#                     [row[col_name] for col_name in column_names if col_name not in categorical_cols]\n",
    "    \n",
    "#     # Return the selected columns as a tuple\n",
    "#     return tuple(selected_cols)\n",
    "\n",
    "# # Initialize StringIndexer and OneHotEncoder objects\n",
    "# string_indexers = [StringIndexer(inputCol=col_name, outputCol=col_name + \"_index\") for col_name in categorical_cols]\n",
    "# encoders = [OneHotEncoder(inputCols=[col_name + \"_index\"], outputCols=[col_name + \"_encoded\"]) for col_name in categorical_cols]\n",
    "\n",
    "# # Assuming your RDD contains dictionaries where keys are column names\n",
    "# # and values are corresponding values for each row\n",
    "# parsed_data_rdd = df.rdd.map(lambda row: parse_data_rdd(row, string_indexers, encoders))\n",
    "# print(parsed_data_rdd.collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531e1384-8291-4629-88d2-30e8f2ae90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "# from pyspark.sql.functions import col\n",
    "\n",
    "# def parse_data(df):\n",
    "#     # Apply StringIndexer and OneHotEncoder to categorical columns\n",
    "#     for col_name in categorical_cols:\n",
    "#         string_indexer = StringIndexer(inputCol=col_name, outputCol=col_name + \"_index\")\n",
    "#         df = string_indexer.fit(df).transform(df)\n",
    "#         encoder = OneHotEncoder(inputCols=[col_name + \"_index\"], outputCols=[col_name + \"_encoded\"])\n",
    "#         df = encoder.fit(df).transform(df)\n",
    "\n",
    "#     # Select only the features and label columns\n",
    "#     selected_cols = [col(col_name + \"_encoded\") for col_name in categorical_cols] + \\\n",
    "#                     [col(col_name) for col_name in column_names if col_name not in categorical_cols]\n",
    "#     parsed_data = df.select(selected_cols)\n",
    "   \n",
    "\n",
    "\n",
    "#     return parsed_data,selected_cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c7498fe-fd63-4d36-9ede-7bca26db6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+-------------------+------------------------+-----------------------------+------------------------------+------------------+--------------------------+------------------+---------------------+-----------------+------------------+---------------------------+------+-------------------+------------------+-------+----------+-------+--------------------+------------+---------+--------+----+-----------------+-----------------+-----+\n",
      "|name_encoded       |summary_encoded   |space_encoded     |description_encoded|instant_bookable_encoded|neighborhood_overview_encoded|neighbourhood_cleansed_encoded|host_name_encoded |host_response_time_encoded|street_encoded    |property_type_encoded|room_type_encoded|amenities_encoded |cancellation_policy_encoded|id    |longitude          |latitude          |host_id|host_since|zipcode|review_scores_rating|accommodates|bathrooms|bedrooms|beds|reviews_per_month|number_of_reviews|price|\n",
      "+-------------------+------------------+------------------+-------------------+------------------------+-----------------------------+------------------------------+------------------+--------------------------+------------------+---------------------+-----------------+------------------+---------------------------+------+-------------------+------------------+-------+----------+-------+--------------------+------------+---------+--------+----+-----------------+-----------------+-----+\n",
      "|(2847,[2448],[1.0])|(2587,[0],[1.0])  |(2477,[867],[1.0])|(2805,[1287],[1.0])|(1,[0],[1.0])           |(1983,[0],[1.0])             |(86,[18],[1.0])               |(1195,[240],[1.0])|(4,[1],[1.0])             |(1244,[443],[1.0])|(14,[1],[1.0])       |(2,[0],[1.0])    |(2468,[48],[1.0]) |(2,[1],[1.0])              |241032|-122.37102519997764|47.636289038357184|956883 |2011-08-11|98119  |95.0                |4           |1.0      |1.0     |1.0 |4.07             |207              |85.0 |\n",
      "|(2847,[517],[1.0]) |(2587,[533],[1.0])|(2477,[311],[1.0])|(2805,[552],[1.0]) |(1,[0],[1.0])           |(1983,[78],[1.0])            |(86,[18],[1.0])               |(1195,[37],[1.0]) |(4,[0],[1.0])             |(1244,[47],[1.0]) |(14,[1],[1.0])       |(2,[0],[1.0])    |(2468,[191],[1.0])|(2,[0],[1.0])              |953595|-122.36566646439582|47.63912312136253 |5177328|2013-02-21|98119  |96.0                |4           |1.0      |1.0     |1.0 |1.48             |43               |150.0|\n",
      "+-------------------+------------------+------------------+-------------------+------------------------+-----------------------------+------------------------------+------------------+--------------------------+------------------+---------------------+-----------------+------------------+---------------------------+------+-------------------+------------------+-------+----------+-------+--------------------+------------+---------+--------+----+-----------------+-----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed_data,new_columns = parse_data(df)\n",
    "parsed_data.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58950a-661a-47a0-9f88-a25a0113c404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
